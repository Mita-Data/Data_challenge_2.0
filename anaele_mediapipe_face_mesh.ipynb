{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mediapipe face mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "# Import required libraries to run the naive baseline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from collections import OrderedDict\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models import mobilenet_v3_small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with the mediapipe face mesh pretrained model\n",
    "# pip install mediapipe\n",
    "\n",
    "\n",
    "\n",
    "# Initialize MediaPipe Face Mesh\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "face_mesh = mp_face_mesh.FaceMesh(static_image_mode=True, max_num_faces=1, min_detection_confidence=0.5)\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# Load your image\n",
    "path = df_train.iloc[0]['filename']\n",
    "image = cv2.imread(path)\n",
    "rgb_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Process the image to find face landmarks\n",
    "results = face_mesh.process(rgb_image)\n",
    "\n",
    "# Create a mask for the skin area\n",
    "mask = np.zeros_like(image)\n",
    "\n",
    "# Define indices for the facial landmarks that typically represent the skin area\n",
    "# These are example indices and may need refinement for your specific case\n",
    "skin_landmark_indices = list(range(0, 468))  # Indices for all landmarks\n",
    "\n",
    "if results.multi_face_landmarks:\n",
    "    for face_landmarks in results.multi_face_landmarks:\n",
    "        points = []\n",
    "        for idx in skin_landmark_indices:\n",
    "            x = int(face_landmarks.landmark[idx].x * image.shape[1])\n",
    "            y = int(face_landmarks.landmark[idx].y * image.shape[0])\n",
    "            points.append([x, y])\n",
    "        \n",
    "        points = np.array(points)\n",
    "        \n",
    "        # Create a convex hull around the skin landmarks to approximate the skin area\n",
    "        hull = cv2.convexHull(points)\n",
    "        \n",
    "        # Draw the convex hull on the mask\n",
    "        cv2.fillConvexPoly(mask, hull, (255, 255, 255))\n",
    "\n",
    "# Apply the mask to the original image\n",
    "skin_area = cv2.bitwise_and(image, mask)\n",
    "\n",
    "# Display the mask and the resulting skin area\n",
    "cv2.imshow('Mask', mask)\n",
    "cv2.imshow('Skin Area', skin_area)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python WSL (myenv)",
   "language": "python",
   "name": "myenv"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
