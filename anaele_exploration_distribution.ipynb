{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CHECKING PIXEL DISTRIBUTION**\n",
    "---\n",
    "\n",
    "***Our train and test dataset are drawn out of 3 different datasets***, which characteristic may vary (different sources ?). We need to check if the pixel distribution among the datasets are equivalent, as composition differ between train and test:<br>\n",
    "  - ***train dataset*** : 1st datbase 29.6%, 2nd database 1.3% and 3rd database 69%.\n",
    "  - ***test dataset*** : 1st dataset 0%, 2nd dataset 1.7% and 3er datase 98.3% \n",
    "  \n",
    "If there are strong pixel distribution differences between datasets, we will need to transform images from 1st and 2nd database to look like images from the 3rd database (cf domain adapatation techniques), because our test dataset comes almost exclusively from the 3rd dataset (98.3%). \n",
    "\n",
    "Also we need to explore ***black and white images*** in the datases, as they would artificially alter the distribution. We create a specific function is_color_image(), to check this in both the train and test dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prerequisites\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "from torchvision.utils import save_image\n",
    "from torch.utils.data import Dataset, DataLoader, ConcatDataset, Subset\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import IPython.display\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from PIL import Image\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "#---------------------------------------\n",
    "# DEFINE DEVICE\n",
    "#---------------------------------------\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = \"mps\"\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "print(device)\n",
    "\n",
    "#---------------------------------------\n",
    "# DEFINE DATASET CLASS\n",
    "#---------------------------------------\n",
    "\n",
    "#class Dataset(torch.utils.data.Dataset): # in \"starter notebook code\" dataset is imported from torch.utils.data\n",
    "class Dataset(Dataset):\n",
    "    'Characterizes a dataset for PyTorch'\n",
    "    def __init__(self, df, image_dir):\n",
    "         'Initialization'\n",
    "         self.image_dir = image_dir\n",
    "         self.df = df\n",
    "         self.transform = transforms.ToTensor()\n",
    "         \n",
    "    def __len__(self):\n",
    "        'Denotes the total number of samples'\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generates one sample of data'\n",
    "        # Select sample\n",
    "        row = self.df.loc[index]\n",
    "        filename = row['filename']\n",
    "\n",
    "        # Load data and get label\n",
    "        img = Image.open(f\"{self.image_dir}/{filename}\")  \n",
    "        X = self.transform(img)\n",
    "\n",
    "        y = row['FaceOcclusion']     \n",
    "        y = np.float32(y)\n",
    "\n",
    "        gender = row['gender_id'] # changed to have round values 0 or 1\n",
    "\n",
    "        return X, y, gender, filename\n",
    "\n",
    "#--------------------------------------------------\n",
    "# Compute mean and standard deviation on the pixels\n",
    "#--------------------------------------------------\n",
    "\n",
    "def calculate_mean_std(loader, num_channels=3):\n",
    "    '''Calculate mean and standard deviation of the dataset.\n",
    "    Args:\n",
    "        loader: DataLoader object\n",
    "        num_channels: number of channels\n",
    "    Returns:\n",
    "        mean: mean of the dataset (tensor)\n",
    "        std: standard deviation of the dataset (tensor)\n",
    "    '''\n",
    "    channel_sum = torch.zeros(num_channels).to(device)\n",
    "    channel_squared_sum = torch.zeros(num_channels).to(device)\n",
    "    num_elements = 0\n",
    "\n",
    "    for data, _, _, _ in loader:\n",
    "        data = data.to(device)\n",
    "        channel_sum += data.sum(dim=[0, 2, 3])\n",
    "        channel_squared_sum += (data ** 2).sum(dim=[0, 2, 3])\n",
    "        num_elements += data.size(0) * data.size(2) * data.size(3)\n",
    "\n",
    "    mean = channel_sum / num_elements\n",
    "    std = (channel_squared_sum / num_elements - mean ** 2) ** 0.5\n",
    "    return mean, std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOAD IMAGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['filename', 'FaceOcclusion', 'gender', 'initial_index', 'gender_id',\n",
      "       'db_number', 'count', 'color', 'image_width', 'image_height',\n",
      "       'channels', 'pixels', 'no_color'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>FaceOcclusion</th>\n",
       "      <th>gender</th>\n",
       "      <th>initial_index</th>\n",
       "      <th>gender_id</th>\n",
       "      <th>db_number</th>\n",
       "      <th>count</th>\n",
       "      <th>color</th>\n",
       "      <th>image_width</th>\n",
       "      <th>image_height</th>\n",
       "      <th>channels</th>\n",
       "      <th>pixels</th>\n",
       "      <th>no_color</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>database1/img00011271.jpg</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.999</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>224</td>\n",
       "      <td>224</td>\n",
       "      <td>3</td>\n",
       "      <td>50176</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>database1/img00012471.jpg</td>\n",
       "      <td>0.035</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>224</td>\n",
       "      <td>224</td>\n",
       "      <td>3</td>\n",
       "      <td>50176</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>database1/img00008127.jpg</td>\n",
       "      <td>0.127</td>\n",
       "      <td>0.001</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>224</td>\n",
       "      <td>224</td>\n",
       "      <td>3</td>\n",
       "      <td>50176</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>database1/img00008972.jpg</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.999</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>224</td>\n",
       "      <td>224</td>\n",
       "      <td>3</td>\n",
       "      <td>50176</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>database1/img00028187.jpg</td>\n",
       "      <td>0.346</td>\n",
       "      <td>0.982</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>224</td>\n",
       "      <td>224</td>\n",
       "      <td>3</td>\n",
       "      <td>50176</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101335</th>\n",
       "      <td>database3/database3/m.01drbr/73-FaceId-0_align...</td>\n",
       "      <td>0.290</td>\n",
       "      <td>0.999</td>\n",
       "      <td>101335</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>224</td>\n",
       "      <td>224</td>\n",
       "      <td>3</td>\n",
       "      <td>50176</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101336</th>\n",
       "      <td>database3/database3/m.01drbr/76-FaceId-0_align...</td>\n",
       "      <td>0.005</td>\n",
       "      <td>1.000</td>\n",
       "      <td>101336</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>224</td>\n",
       "      <td>224</td>\n",
       "      <td>3</td>\n",
       "      <td>50176</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101337</th>\n",
       "      <td>database3/database3/m.01drbr/79-FaceId-0_align...</td>\n",
       "      <td>0.105</td>\n",
       "      <td>1.000</td>\n",
       "      <td>101337</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>224</td>\n",
       "      <td>224</td>\n",
       "      <td>3</td>\n",
       "      <td>50176</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101338</th>\n",
       "      <td>database3/database3/m.01drbr/80-FaceId-0_align...</td>\n",
       "      <td>0.241</td>\n",
       "      <td>0.999</td>\n",
       "      <td>101338</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>224</td>\n",
       "      <td>224</td>\n",
       "      <td>3</td>\n",
       "      <td>50176</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101339</th>\n",
       "      <td>database3/database3/m.01drbr/81-FaceId-0_align...</td>\n",
       "      <td>0.109</td>\n",
       "      <td>0.999</td>\n",
       "      <td>101339</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>224</td>\n",
       "      <td>224</td>\n",
       "      <td>3</td>\n",
       "      <td>50176</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>101336 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 filename  FaceOcclusion  \\\n",
       "0                               database1/img00011271.jpg          0.019   \n",
       "1                               database1/img00012471.jpg          0.035   \n",
       "2                               database1/img00008127.jpg          0.127   \n",
       "3                               database1/img00008972.jpg          0.014   \n",
       "4                               database1/img00028187.jpg          0.346   \n",
       "...                                                   ...            ...   \n",
       "101335  database3/database3/m.01drbr/73-FaceId-0_align...          0.290   \n",
       "101336  database3/database3/m.01drbr/76-FaceId-0_align...          0.005   \n",
       "101337  database3/database3/m.01drbr/79-FaceId-0_align...          0.105   \n",
       "101338  database3/database3/m.01drbr/80-FaceId-0_align...          0.241   \n",
       "101339  database3/database3/m.01drbr/81-FaceId-0_align...          0.109   \n",
       "\n",
       "        gender  initial_index  gender_id  db_number  count  color  \\\n",
       "0        0.999              0          1          1      1      1   \n",
       "1        1.000              1          1          1      1      1   \n",
       "2        0.001              2          0          1      1      1   \n",
       "3        0.999              3          1          1      1      1   \n",
       "4        0.982              4          1          1      1      1   \n",
       "...        ...            ...        ...        ...    ...    ...   \n",
       "101335   0.999         101335          1          3      1      0   \n",
       "101336   1.000         101336          1          3      1      1   \n",
       "101337   1.000         101337          1          3      1      1   \n",
       "101338   0.999         101338          1          3      1      0   \n",
       "101339   0.999         101339          1          3      1      1   \n",
       "\n",
       "        image_width  image_height  channels  pixels  no_color  \n",
       "0               224           224         3   50176         0  \n",
       "1               224           224         3   50176         0  \n",
       "2               224           224         3   50176         0  \n",
       "3               224           224         3   50176         0  \n",
       "4               224           224         3   50176         0  \n",
       "...             ...           ...       ...     ...       ...  \n",
       "101335          224           224         3   50176         1  \n",
       "101336          224           224         3   50176         0  \n",
       "101337          224           224         3   50176         0  \n",
       "101338          224           224         3   50176         1  \n",
       "101339          224           224         3   50176         0  \n",
       "\n",
       "[101336 rows x 13 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LOAD DATAFRAMES\n",
    "\n",
    "with open('df_train.pkl', 'rb') as f: df_train = pickle.load(f)\n",
    "\n",
    "with open('df_test.pkl', 'rb') as f: df_test = pickle.load(f)\n",
    "# add columns to use the same Dataset class for df_train and df_test\n",
    "df_test['FaceOcclusion'] = -1.0 # float\n",
    "df_test['gender']= -1.0 # float\n",
    "df_test['gender_id'] = -1 # integer\n",
    "\n",
    "print(df_train.columns)\n",
    "df_train.head(-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1/ Explore weight of black and white images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3132/2636741972.py:3: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  stats = df_train.groupby('db_number')['count','color','no_color','FaceOcclusion','gender_id'].sum()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>color</th>\n",
       "      <th>no_color</th>\n",
       "      <th>FaceOcclusion</th>\n",
       "      <th>gender_id</th>\n",
       "      <th>color_ratio</th>\n",
       "      <th>FaceOcclusion_ratio</th>\n",
       "      <th>gender_ratio</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>db_number</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30000.0</td>\n",
       "      <td>30000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3426.257</td>\n",
       "      <td>10845.0</td>\n",
       "      <td>100.00%</td>\n",
       "      <td>0.114209</td>\n",
       "      <td>36.15%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1345.0</td>\n",
       "      <td>1234.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>174.677</td>\n",
       "      <td>717.0</td>\n",
       "      <td>91.75%</td>\n",
       "      <td>0.129871</td>\n",
       "      <td>53.31%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>69996.0</td>\n",
       "      <td>56032.0</td>\n",
       "      <td>13964.0</td>\n",
       "      <td>5293.621</td>\n",
       "      <td>49352.0</td>\n",
       "      <td>80.05%</td>\n",
       "      <td>0.075627</td>\n",
       "      <td>70.51%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total</th>\n",
       "      <td>101341.0</td>\n",
       "      <td>87266.0</td>\n",
       "      <td>14075.0</td>\n",
       "      <td>8894.555</td>\n",
       "      <td>60914.0</td>\n",
       "      <td>86.11%</td>\n",
       "      <td>0.087769</td>\n",
       "      <td>60.11%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              count    color  no_color  FaceOcclusion  gender_id color_ratio  \\\n",
       "db_number                                                                      \n",
       "1           30000.0  30000.0       0.0       3426.257    10845.0     100.00%   \n",
       "2            1345.0   1234.0     111.0        174.677      717.0      91.75%   \n",
       "3           69996.0  56032.0   13964.0       5293.621    49352.0      80.05%   \n",
       "Total      101341.0  87266.0   14075.0       8894.555    60914.0      86.11%   \n",
       "\n",
       "           FaceOcclusion_ratio gender_ratio  \n",
       "db_number                                    \n",
       "1                     0.114209       36.15%  \n",
       "2                     0.129871       53.31%  \n",
       "3                     0.075627       70.51%  \n",
       "Total                 0.087769       60.11%  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TRAIN - Distribution of color and black and white images (gray scale) in the 3 datasets\n",
    "\n",
    "stats = df_train.groupby('db_number')['count','color','no_color','FaceOcclusion','gender_id'].sum()\n",
    "stats.loc['Total'] = stats.sum()\n",
    "stats['color_ratio'] = stats['color'] / stats['count']\n",
    "stats['FaceOcclusion_ratio'] = stats['FaceOcclusion'] / stats['count'] # average FaceOcclusion\n",
    "stats['color_ratio'] = stats['color_ratio'].map('{:.2%}'.format)\n",
    "stats['gender_ratio'] = stats['gender_id'] / stats['count']\n",
    "stats['gender_ratio'] = stats['gender_ratio'].map('{:.2%}'.format)\n",
    "stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3132/527400356.py:3: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  stats = df_test.groupby('db_number')['count','color','no_color'].sum()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>color</th>\n",
       "      <th>no_color</th>\n",
       "      <th>color_ratio</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>db_number</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>507</td>\n",
       "      <td>475</td>\n",
       "      <td>32</td>\n",
       "      <td>93.69%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30000</td>\n",
       "      <td>24151</td>\n",
       "      <td>5849</td>\n",
       "      <td>80.50%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total</th>\n",
       "      <td>30507</td>\n",
       "      <td>24626</td>\n",
       "      <td>5881</td>\n",
       "      <td>80.72%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           count  color  no_color color_ratio\n",
       "db_number                                    \n",
       "2            507    475        32      93.69%\n",
       "3          30000  24151      5849      80.50%\n",
       "Total      30507  24626      5881      80.72%"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TEST DATASET - Distribution of color and black and white images (gray scale) in the 3 datasets\n",
    "\n",
    "stats = df_test.groupby('db_number')['count','color','no_color'].sum()\n",
    "stats.loc['Total'] = stats.sum()\n",
    "stats['color_ratio'] = stats['color'] / stats['count']\n",
    "stats['color_ratio'] = stats['color_ratio'].map('{:.2%}'.format)\n",
    "stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "# =======> Black and white images can be removed from the train datasets\n",
    "# !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>color</th>\n",
       "      <th>no_color</th>\n",
       "      <th>FaceOcclusion</th>\n",
       "      <th>gender_id</th>\n",
       "      <th>color_ratio</th>\n",
       "      <th>FaceOcclusion_ratio</th>\n",
       "      <th>gender_ratio</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>db_number</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30000.0</td>\n",
       "      <td>30000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3426.257</td>\n",
       "      <td>10845.0</td>\n",
       "      <td>100.00%</td>\n",
       "      <td>0.114209</td>\n",
       "      <td>36.15%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1234.0</td>\n",
       "      <td>1234.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>164.645</td>\n",
       "      <td>640.0</td>\n",
       "      <td>100.00%</td>\n",
       "      <td>0.133424</td>\n",
       "      <td>51.86%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56032.0</td>\n",
       "      <td>56032.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4320.100</td>\n",
       "      <td>39582.0</td>\n",
       "      <td>100.00%</td>\n",
       "      <td>0.077101</td>\n",
       "      <td>70.64%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total</th>\n",
       "      <td>87266.0</td>\n",
       "      <td>87266.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7911.002</td>\n",
       "      <td>51067.0</td>\n",
       "      <td>100.00%</td>\n",
       "      <td>0.090654</td>\n",
       "      <td>58.52%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             count    color  no_color  FaceOcclusion  gender_id color_ratio  \\\n",
       "db_number                                                                     \n",
       "1          30000.0  30000.0       0.0       3426.257    10845.0     100.00%   \n",
       "2           1234.0   1234.0       0.0        164.645      640.0     100.00%   \n",
       "3          56032.0  56032.0       0.0       4320.100    39582.0     100.00%   \n",
       "Total      87266.0  87266.0       0.0       7911.002    51067.0     100.00%   \n",
       "\n",
       "           FaceOcclusion_ratio gender_ratio  \n",
       "db_number                                    \n",
       "1                     0.114209       36.15%  \n",
       "2                     0.133424       51.86%  \n",
       "3                     0.077101       70.64%  \n",
       "Total                 0.090654       58.52%  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TRAIN - Distribution of color images (gray scale) in the 3 datasets\n",
    "\n",
    "stats_color = df_train[df_train['color']==1].groupby('db_number')[['count','color','no_color','FaceOcclusion','gender_id']].sum()\n",
    "stats_color.loc['Total'] = stats_color.sum()\n",
    "stats_color['color_ratio'] = stats_color['color'] / stats_color['count']\n",
    "stats_color['FaceOcclusion_ratio'] = stats_color['FaceOcclusion'] / stats_color['count'] # average FaceOcclusion\n",
    "stats_color['color_ratio'] = stats_color['color_ratio'].map('{:.2%}'.format)\n",
    "stats_color['gender_ratio'] = stats_color['gender_id'] / stats_color['count']\n",
    "stats_color['gender_ratio'] = stats_color['gender_ratio'].map('{:.2%}'.format)\n",
    "stats_color"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2/ Explore color image pixel distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1/ Train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df shape: (87266, 14)\n",
      "df_1 shape: (30000, 14)\n",
      "df_2 shape: (1234, 14)\n",
      "df_3 shape: (56032, 14)\n",
      "train color - mean       [0.55681306 0.43925527 0.38031614] std [0.28266945 0.24948709 0.24216673]\n",
      "database 1 color - mean  [0.5637954  0.43052804 0.36255956] std [0.2892353  0.2503865  0.23815684]\n",
      "database 2 color - mean  [0.5349409  0.4159749  0.35325104] std [0.3020055  0.26349074 0.25038993]\n",
      "database 3 color - mean  [0.55355614 0.44444054 0.3904193 ] std [0.2785599  0.24852644 0.24351525]\n"
     ]
    }
   ],
   "source": [
    "# split dataframes by database source and take only color images\n",
    "df = df_train[df_train['color']==1].reset_index(drop=True)\n",
    "df_1 = df_train[(df_train['db_number'] == 1) & (df_train['color'] == 1)].reset_index(drop=True)\n",
    "df_2 = df_train[(df_train['db_number'] == 2) & (df_train['color'] == 1)].reset_index(drop=True)\n",
    "df_3 = df_train[(df_train['db_number'] == 3) & (df_train['color'] == 1)].reset_index(drop=True)\n",
    "\n",
    "# print shapes\n",
    "print('df shape:', df.shape)\n",
    "print('df_1 shape:', df_1.shape)\n",
    "print('df_2 shape:', df_2.shape)\n",
    "print('df_3 shape:', df_3.shape)\n",
    "\n",
    "# generate datasets for database 1 and 3\n",
    "image_dir = 'Data/crops_100K'\n",
    "set = Dataset(df, image_dir)\n",
    "set_1 = Dataset(df_1, image_dir)\n",
    "set_2 = Dataset(df_2, image_dir)\n",
    "set_3 = Dataset(df_3, image_dir)\n",
    "\n",
    "# Create DataLoaders\n",
    "params = {'batch_size': 1024,\n",
    "          'shuffle': False,\n",
    "          'num_workers': 0}\n",
    "\n",
    "loader = torch.utils.data.DataLoader(set, **params)\n",
    "loader_1 = torch.utils.data.DataLoader(set_1, **params)\n",
    "loader_2 = torch.utils.data.DataLoader(set_2, **params)\n",
    "loader_3 = torch.utils.data.DataLoader(set_3, **params)\n",
    "\n",
    "# compute mean and standard deviation for the color images in the 3 datasets\n",
    "mean , std = calculate_mean_std(loader, num_channels=3)\n",
    "print('train color - mean      ', mean.cpu().numpy(), 'std', std.cpu().numpy())\n",
    "mean_1, std_1 = calculate_mean_std(loader_1, num_channels=3)\n",
    "print('database 1 color - mean ', mean_1.cpu().numpy(), 'std', std_1.cpu().numpy())\n",
    "mean_2, std_2 = calculate_mean_std(loader_2, num_channels=3)\n",
    "print('database 2 color - mean ', mean_2.cpu().numpy(), 'std', std_2.cpu().numpy())\n",
    "mean_3, std_3 = calculate_mean_std(loader_3, num_channels=3)\n",
    "print('database 3 color - mean ', mean_3.cpu().numpy(), 'std', std_3.cpu().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute mean and std deviation of each channel for each dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "database 1+2 color - mean  [0.5626554  0.42995307 0.36219183] std [0.28980505 0.25093326 0.23865889]\n",
      "database 3 color - mean    [0.55355614 0.44444054 0.3904193 ] std [0.2785599  0.24852644 0.24351525]\n"
     ]
    }
   ],
   "source": [
    "# concatenate dataset 1 + 2\n",
    "df_12 = pd.concat([df_1, df_2])\n",
    "df_12 = df_12.reset_index(drop=True)\n",
    "set_12 = Dataset(df_12, image_dir)\n",
    "loader_12 = torch.utils.data.DataLoader(set_12, **params)\n",
    "\n",
    "mean_12, std_12 = calculate_mean_std(loader_12, num_channels=3)\n",
    "print('database 1+2 color - mean ', mean_12.cpu().numpy(), 'std', std_12.cpu().numpy())\n",
    "print('database 3 color - mean   ', mean_3.cpu().numpy(), 'std', std_3.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# database 1 - mean  tensor([0.5623, 0.4301, 0.3626], device='cuda:0')\n",
    "# database 1 - std tensor([0.2899, 0.2511, 0.2390], device='cuda:0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.2/ Test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test df shape: (24626, 13)\n",
      "test df_1 shape: (0, 13)\n",
      "test df_2 shape: (475, 13)\n",
      "test df_3 shape: (24151, 13)\n",
      "\n",
      "test color - mean        [0.546068   0.43837228 0.38533455] std [0.28526616 0.25515932 0.24864335]\n",
      "database 2 color - mean  [0.5148032  0.41072243 0.36299762] std [0.3153239  0.27922863 0.26618573]\n",
      "database 3 color - mean  [0.5466831  0.43891606 0.3857739 ] std [0.28460854 0.25463304 0.24826565]\n"
     ]
    }
   ],
   "source": [
    "# split dataframes by database source and take only color images\n",
    "df_test = df_test[df_test['color']==1].reset_index(drop=True)\n",
    "df_1_test = df_test[(df_test['db_number'] == 1) & (df_test['color'] == 1)].reset_index(drop=True)\n",
    "df_2_test = df_test[(df_test['db_number'] == 2) & (df_test['color'] == 1)].reset_index(drop=True)\n",
    "df_3_test = df_test[(df_test['db_number'] == 3) & (df_test['color'] == 1)].reset_index(drop=True)\n",
    "\n",
    "# print shapes\n",
    "print('test df shape:', df_test.shape)\n",
    "print('test df_1 shape:', df_1_test.shape)\n",
    "print('test df_2 shape:', df_2_test.shape)\n",
    "print('test df_3 shape:', df_3_test.shape)\n",
    "\n",
    "# generate datasets for database 2 and 3\n",
    "image_dir = 'Data/crops_100K'\n",
    "set_test = Dataset(df_test, image_dir)\n",
    "# set_1_test = Dataset(df_1_test, image_dir)\n",
    "set_2_test = Dataset(df_2_test, image_dir)\n",
    "set_3_test = Dataset(df_3_test, image_dir)\n",
    "\n",
    "# Create DataLoaders\n",
    "params = {'batch_size': 1024,\n",
    "          'shuffle': False,\n",
    "          'num_workers': 0}\n",
    "loader_test = torch.utils.data.DataLoader(set_test, **params)\n",
    "# loader_1 = torch.utils.data.DataLoader(set_1, **params)\n",
    "loader_2_test = torch.utils.data.DataLoader(set_2_test, **params)\n",
    "loader_3_test = torch.utils.data.DataLoader(set_3_test, **params)\n",
    "\n",
    "# Compute mean and standard deviation of the pixels in color images in test dataset\n",
    "mean_test , std_test = calculate_mean_std(loader_test, num_channels=3)\n",
    "print('\\ntest color - mean       ', mean_test.cpu().numpy(), 'std', std_test.cpu().numpy())\n",
    "mean_2_test, std_2_test = calculate_mean_std(loader_2_test, num_channels=3)\n",
    "print('database 2 color - mean ', mean_2_test.cpu().numpy(), 'std', std_2_test.cpu().numpy())\n",
    "mean_3_test, std_3_test = calculate_mean_std(loader_3_test, num_channels=3)\n",
    "print('database 3 color - mean ', mean_3_test.cpu().numpy(), 'std', std_3_test.cpu().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3/ by genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WOMEN - PIXEL DISTRIBUTION ACCROSS DATASETS\n",
      "women:     [0.5663897  0.4420299  0.37423137] std [0.2842709  0.25059035 0.2395299 ]\n",
      "women db1: [0.57377017 0.43721    0.36410475] std [0.2888427  0.25140956 0.237155  ]\n",
      "women db2: [0.5253696  0.40710264 0.3474076 ] std [0.2981118  0.25932735 0.24827269]\n",
      "women db3: [0.55855876 0.44823802 0.38655362] std [0.27777538 0.24884431 0.24121183]\n",
      "\n",
      "MEN - PIXEL DISTRIBUTION ACCROSS DATASETS\n",
      "\n",
      "men: [0.5500244 0.4372884 0.3846294] std [0.28133184 0.24868338 0.24392666]\n",
      "men db1: [0.5461774  0.41872615 0.3598304 ] std [0.28908795 0.24813004 0.23989168]\n",
      "men db2: [0.5253696  0.40710264 0.3474076 ] std [0.2981118  0.25932735 0.24827269]\n",
      "men db3: [0.5514772  0.44286242 0.3920259 ] std [0.2788585  0.24837685 0.24444811]\n"
     ]
    }
   ],
   "source": [
    "image_dir = 'Data/crops_100K'\n",
    "\n",
    "women = df_train[(df_train['gender_id'] == 0)&(df_train['color'] == 1)].reset_index(drop=True)\n",
    "women_1 = women[ women['db_number'] == 1].reset_index(drop=True)\n",
    "women_2 = women[ women['db_number'] == 2].reset_index(drop=True)\n",
    "women_3 = women[ women['db_number'] == 3].reset_index(drop=True)\n",
    "\n",
    "men = df_train[(df_train['gender_id'] == 1)&(df_train['color'] == 1)].reset_index(drop=True)\n",
    "men_1 =men[ men['db_number'] == 1].reset_index(drop=True)\n",
    "men_2 = men[men['db_number'] == 2].reset_index(drop=True)\n",
    "men_3 = men[men['db_number'] == 3].reset_index(drop=True)\n",
    "\n",
    "set_w = Dataset(women, image_dir)\n",
    "set_w_1 = Dataset(women_1, image_dir)\n",
    "set_w_2 = Dataset(women_2, image_dir)\n",
    "set_w_3 = Dataset(women_3, image_dir)\n",
    "\n",
    "set_m = Dataset(men, image_dir)\n",
    "set_m_1 = Dataset(men_1, image_dir)\n",
    "set_m_2 = Dataset(men_2, image_dir)\n",
    "set_m_3 = Dataset(men_3, image_dir)\n",
    "\n",
    "params = {'batch_size': 1024,\n",
    "          'shuffle': False,\n",
    "          'num_workers': 0}\n",
    "\n",
    "loader_w = torch.utils.data.DataLoader(set_w, **params)\n",
    "loader_w_1 = torch.utils.data.DataLoader(set_w_1, **params)\n",
    "loader_w_2 = torch.utils.data.DataLoader(set_w_2, **params)\n",
    "loader_w_3 = torch.utils.data.DataLoader(set_w_3, **params)\n",
    "loader_m = torch.utils.data.DataLoader(set_m, **params)\n",
    "loader_m_1 = torch.utils.data.DataLoader(set_m_1, **params)\n",
    "loader_m_2 = torch.utils.data.DataLoader(set_m_2, **params)\n",
    "loader_m_3 = torch.utils.data.DataLoader(set_m_3, **params)\n",
    "\n",
    "# Pixel mean by gender and channel\n",
    "print('\\nWOMEN - PIXEL DISTRIBUTION ACCROSS DATASETS')\n",
    "mean_w, std_w = calculate_mean_std(loader_w, num_channels=3)\n",
    "print('women:    ', mean_w.cpu().numpy(), 'std', std_w.cpu().numpy())\n",
    "mean_w_1, std_w_1 = calculate_mean_std(loader_w_1, num_channels=3)\n",
    "print('women db1:', mean_w_1.cpu().numpy(), 'std', std_w_1.cpu().numpy())\n",
    "mean_w_2, std_w_2 = calculate_mean_std(loader_m_2, num_channels=3)\n",
    "print('women db2:', mean_w_2.cpu().numpy(), 'std', std_w_2.cpu().numpy())\n",
    "mean_w_3, std_w_3 = calculate_mean_std(loader_w_3, num_channels=3)\n",
    "print('women db3:', mean_w_3.cpu().numpy(), 'std', std_w_3.cpu().numpy())\n",
    "\n",
    "print('\\nMEN - PIXEL DISTRIBUTION ACCROSS DATASETS')\n",
    "mean_m, std_m = calculate_mean_std(loader_m, num_channels=3)\n",
    "print('men:    ', mean_m.cpu().numpy(), 'std', std_m.cpu().numpy())\n",
    "mean_m_1, std_m_1 = calculate_mean_std(loader_m_1, num_channels=3)\n",
    "print('men db1:', mean_m_1.cpu().numpy(), 'std', std_m_1.cpu().numpy())\n",
    "mean_m_2, std_m_2 = calculate_mean_std(loader_m_2, num_channels=3)\n",
    "print('men db2:', mean_m_2.cpu().numpy(), 'std', std_m_2.cpu().numpy())\n",
    "mean_m_3, std_m_3 = calculate_mean_std(loader_m_3, num_channels=3)\n",
    "print('men db3:', mean_m_3.cpu().numpy(), 'std', std_m_3.cpu().numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "color, women, occlusion level 0: mean [0.5771184  0.45563287 0.38917598], std [0.28269112 0.25121826 0.24201731], 15470 images\n",
      "color, women, occlusion level 1: mean [0.56732756 0.43869033 0.36858016], std [0.28308097 0.24775174 0.2354804 ], 12384 images\n",
      "color, women, occlusion level 2: mean [0.5459979  0.4225831  0.35457334], std [0.28528833 0.2492176  0.23634155], 5520 images\n",
      "color, women, occlusion level 3: mean [0.5380704  0.41235062 0.34596163], std [0.29154342 0.25424272 0.23983368], 2237 images\n",
      "color, women, occlusion level 4: mean [0.5101596  0.3951852  0.34012443], std [0.30822027 0.26905623 0.2500039 ], 251 images\n",
      "color, women, occlusion level 5: mean [0.49181914 0.40398246 0.3642229 ], std [0.3078752  0.26975113 0.25469872], 20 images\n",
      "color, women, occlusion level 6: mean [0.5748995  0.4025202  0.35526362], std [0.27476484 0.275585   0.2941789 ], 6 images\n",
      "color, women, occlusion level 7: mean [0.5339146  0.5094275  0.40241918], std [0.28971347 0.27086028 0.24094361], 2 images\n",
      "color, women, occlusion level 8: mean [0.5592626  0.47406742 0.4430968 ], std [0.25524175 0.24820149 0.23111215], 2 images\n",
      "color, women, occlusion level 9: mean [nan nan nan], std [nan nan nan], 0 images\n"
     ]
    }
   ],
   "source": [
    "# DISTRIBUTION BY LEVEL OF OCCLUSION FOR WOMEN AND COLOR IMAGES\n",
    "# -------------------------------------------------------------\n",
    "list = np.arange(0 , 1 , 0.1).tolist()\n",
    "df_train['occ_level'] = pd.cut(df_train['FaceOcclusion'], bins=list, labels=False)\n",
    "\n",
    "\n",
    "df_color_w = df_train[ (df_train['color'] == 1) & (df_train['gender_id']==0)].reset_index(drop=True)\n",
    "res = []\n",
    "for i in range(0,10):\n",
    "    df_ = df_color_w[df_color_w['occ_level'] == i].reset_index(drop=True)\n",
    "    set_ = Dataset(df_, image_dir)\n",
    "    loader_ = torch.utils.data.DataLoader(set_, **params)\n",
    "    mean_, std_ = calculate_mean_std(loader_, num_channels=3)\n",
    "    print(f'color, women, occlusion level {i}: mean {mean_.cpu().numpy()}, std {std_.cpu().numpy()}, {len(df_)} images')\n",
    "    res.append([i, len(df_)] + mean_.cpu().numpy().tolist() + std_.cpu().numpy().tolist())\n",
    "\n",
    "res_df = pd.DataFrame(res, columns=['occ_level','images', 'mean_R','mean_G','mean_B' ,'std_R','std_G','std_B'])\n",
    "with open('pixel_distribution_train_color_w_occ_level.pkl', 'wb') as f: pickle.dump(res_df, f)\n",
    "                                                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x300 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_dist(res_df, title):\n",
    "    res = res_df.iloc[:5,:] # take only first 5 occlusion levels\n",
    "    plt.figure(figsize=(8,3))\n",
    "    \n",
    "    # red channel\n",
    "    plt.subplot(1,3,1)\n",
    "    plt.plot(res['occ_level'], res['mean_R'], color='r', marker='o', label='mean_R')\n",
    "    plt.fill_between(res['occ_level'], res['mean_R']-res['std_R'], res['mean_R']+res['std_R'], color='r', alpha=0.3, label='std_R')\n",
    "    plt.title('Red channel')\n",
    "    plt.xlabel('Occlusion level')\n",
    "    plt.xticks(res['occ_level'])\n",
    "    plt.ylabel('Pixel value [0-1]')\n",
    "    plt.ylim(0,1)\n",
    "    plt.grid(axis='y', linestyle='--', linewidth=0.7)\n",
    "\n",
    "    # green channel\n",
    "    plt.subplot(1,3,2)\n",
    "    plt.plot(res['occ_level'], res['mean_G'], color='g', marker='o', label='mean_G')\n",
    "    plt.fill_between(res['occ_level'], res['mean_G']-res['std_G'], res['mean_G']+res['std_G'], color='g', alpha=0.3, label='std_G')\n",
    "    plt.title('Green channel')\n",
    "    plt.xlabel('Occlusion level\\n\\n0=[0,0.1]  1=[0.1,0.2]  2=[0.2,0.3]  3=[0.3,0.4]  4=[0.4,0.5]')\n",
    "    plt.xticks(res['occ_level'])\n",
    "    plt.ylabel('Pixel value [0-1]')\n",
    "    plt.ylim(0,1)\n",
    "    plt.grid(axis='y', linestyle='--', linewidth=0.7)\n",
    "\n",
    "    # blue channel\n",
    "    plt.subplot(1,3,3)\n",
    "    plt.plot(res['occ_level'], res['mean_B'], color='b', marker='o', label='mean_B')\n",
    "    plt.fill_between(res['occ_level'], res['mean_B']-res['std_B'], res['mean_B']+res['std_B'], color='b', alpha=0.3, label='std_B')\n",
    "    plt.title('Blue channel')\n",
    "    plt.xlabel('Occlusion level')\n",
    "    plt.xticks(res['occ_level'])\n",
    "    plt.ylabel('Pixel value [0-1]')\n",
    "    plt.ylim(0,1)\n",
    "    plt.grid(axis='y', linestyle='--', linewidth=0.7)\n",
    "\n",
    "    plt.subplots_adjust(top=0.8, wspace=0.4)\n",
    "    plt.suptitle(title, fontsize=16)\n",
    "    plt.show()\n",
    "\n",
    "plot_dist(res_df,\"Women (train) - pixel distribution by occlusion level\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3/ Normalize images ?\n",
    "\n",
    "# NO - to avoid losing relationship between pixel levels and occultation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4/ PIXEL DISTRIBUTION OF THE FACE AREA (MASKED IMAGES)\n",
    "\n",
    "TO BE DONE WITH MEDIAPIPE MASKS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4/ PIXEL DISTRIBUTION - COVARIANCE (2nd order statistics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# NORMALIZED DATA\n",
    "#####################################\n",
    "\n",
    "# MNIST\n",
    "data = MNIST_train.data.to(device)\n",
    "data = data.float() \n",
    "#reshape mnist data from 28x28 to 32x32 pixels\n",
    "data = F.interpolate(data.unsqueeze(1), size=(32, 32), mode='nearest').squeeze(1)\n",
    "data = data / 255\n",
    "#print(\"mnist 32x32 shape\",data.shape)\n",
    "data = (data - mnist_mean) / mnist_std\n",
    "mnist_norm_np_flat = data.reshape(data.shape[0], -1).cpu().numpy()\n",
    "\n",
    "# SVHN grayscale (by averaging 3 channels into 1)\n",
    "data = SVHN_train.data /255\n",
    "#print(type(data))\n",
    "data = torch.tensor(data, dtype=torch.float32).to(device)\n",
    "data = torch.mean(data, axis=1)    # reduce to 1 channel\n",
    "data = (data - svhn_mean) / svhn_std\n",
    "data = data.reshape(data.shape[0], -1)\n",
    "svhn_gray_norm_np_flat = data.cpu().numpy()\n",
    "\n",
    "# SVHN  \n",
    "data = SVHN_train.data / 255\n",
    "data = torch.tensor(data, dtype=torch.float32).to(device)\n",
    "data = (data - svhn_mean) / svhn_std\n",
    "svhn_norm_np = data.cpu().numpy()\n",
    "data = data.reshape(data.shape[0], -1)\n",
    "svhn_norm_np_flat = data.cpu().numpy()\n",
    "\n",
    "print(\"\\nNormalised MNIST min, max & shape    :\",mnist_norm_np_flat.shape, mnist_norm_np_flat.min(),mnist_norm_np_flat.max(), type(mnist_norm_np_flat))\n",
    "print(\"Normalised SVHN gray min, max & shape:\",svhn_gray_norm_np_flat.shape, svhn_gray_norm_np_flat.min(), svhn_gray_norm_np_flat.max(), type(svhn_gray_norm_np_flat))\n",
    "print(\"Normalised SVHN min, max & shape     :\",svhn_norm_np_flat.shape, svhn_norm_np_flat.min(),svhn_norm_np_flat.max(),type(svhn_norm_np_flat))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check normalisatoin for Red Green Blue channel of SVHN\n",
    "\n",
    "print(\"\\nSVHN (x3) mean, std   :\",np.round(np.mean(svhn_norm_np_flat),8), np.std(svhn_norm_np_flat), svhn_norm_np_flat.shape)\n",
    "print(\"- SVHN RED mean , std :\",np.mean(svhn_norm_np_flat[:,:1024]), np.std(svhn_norm_np_flat[:,:1024]), svhn_norm_np_flat[:,:1024].shape)\n",
    "print(\"- SVHN GREEN mean, std:\",np.mean(svhn_norm_np_flat[:,1024:2048]), np.std(svhn_norm_np_flat[:,1024:2048]), svhn_norm_np_flat[:,1024:2048].shape)\n",
    "print(\"- SVHN BLUE mean, std : \",np.mean(svhn_norm_np_flat[:,2048:]), np.std(svhn_norm_np_flat[:,2084,]), svhn_norm_np_flat[:,2048:].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################\n",
    "# print images to check normalisation\n",
    "# values range from -inf to +inf => need to scale to 0-1\n",
    "########################################################\n",
    "\n",
    "def plot_images(images, title, color ='gray', scaled = 1):\n",
    "    fig, axs = plt.subplots(1, 10, figsize=(8, 1))\n",
    "    # standardize the range of the images with min or max\n",
    "    for i in range(10):\n",
    "        if scaled == 1:\n",
    "            scaled_image = (images[i]/scale +0.5)\n",
    "            # print('min max:', np.min(scaled_image),' - ', np.max(scaled_image))\n",
    "            # klip the values to 0-1\t\n",
    "            scaled_image[scaled_image > 1] = 1\n",
    "            scaled_image[scaled_image < 0] = 0\n",
    "        else:\n",
    "            scaled_image = images[i]\n",
    "        axs[i].imshow(scaled_image, cmap= color) # scales images to range 0-1\n",
    "        axs[i].axis('off')\n",
    "    plt.suptitle(title, fontsize=14)\n",
    "    plt.show()\n",
    "\n",
    "high = max( np.max(mnist_norm_np_flat) , np.max(svhn_gray_norm_np_flat) , np.max(svhn_norm_np_flat) )\n",
    "low = min( np.min(mnist_norm_np_flat) , np.min(svhn_gray_norm_np_flat), np.min(svhn_norm_np_flat) )\n",
    "scale = max(abs(high), abs(low))\n",
    "print(\"scale\", scale)\n",
    "\n",
    "# MNIST\n",
    "mnist_norm_np = mnist_norm_np_flat.reshape(-1, 32, 32)\n",
    "plot_images(mnist_norm_np, 'MNIST Normalized')\n",
    "\n",
    "# SVHN grayscale\n",
    "svhn_gray_norm_np = svhn_gray_norm_np_flat.reshape(-1, 32, 32)\n",
    "plot_images(svhn_gray_norm_np, 'SVHN Grayscale Normalized')\n",
    "\n",
    "# SVHN\n",
    "svhn_np_transpose = SVHN_train.data.transpose((0, 2, 3, 1))/255\n",
    "plot_images(svhn_np_transpose, 'SVHN Original', scaled = 0)\n",
    "\n",
    "# SVHN\n",
    "svhn_norm_np_transpose = svhn_norm_np.transpose((0, 2, 3, 1))\n",
    "plot_images(svhn_norm_np_transpose, 'SVHN \"Normalized globally\"')\n",
    "#show red channel in red, green in green and blue in blue\n",
    "plot_images(svhn_norm_np_transpose[:,:,:,0], 'SVHN Normalized Red Channel', color ='Reds')\n",
    "plot_images(svhn_norm_np_transpose[:,:,:,1], 'SVHN Normalized Green Channel', color ='Greens')\n",
    "plot_images(svhn_norm_np_transpose[:,:,:,2], 'SVHN Normalized Blue Channel', color ='Blues')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHOW 3 CORRELATION MATRICES (FLATTENED)\n",
    "##########################################\n",
    "\n",
    "cov_mnist_norm = np.cov(mnist_norm_np_flat, rowvar=False)\n",
    "cov_svhn_gray_norm = np.cov(svhn_gray_norm_np_flat, rowvar=False)\n",
    "cov_svhn_norm = np.cov(svhn_norm_np_flat, rowvar=False)\n",
    "\n",
    "# covariance matrix is correlation matrix beacause the data is normalised\n",
    "\n",
    "# Create a figure with subplots\n",
    "fig, axs = plt.subplots(1, 3, figsize=(15, 5.5))  # 1 row, 3 columns\n",
    "vmin = -1\n",
    "vmax = 1\n",
    "# MNIST Correlation Matrix\n",
    "ax = axs[0]  # First subplot for MNIST\n",
    "im = ax.imshow(cov_mnist_norm, cmap='coolwarm', interpolation='none',vmin=vmin, vmax=vmax)\n",
    "ax.grid(True)\n",
    "ax.set_xticks(np.arange(0, 1024, 32))\n",
    "ax.set_yticks(np.arange(0, 1024, 32))\n",
    "ax.set_xticklabels([])\n",
    "ax.set_yticklabels([])\n",
    "ax.set_title('MNIST - Covariance Matrix \\n(1 channel 32x32=1024)')\n",
    "#fig.colorbar(im, ax=ax, )\n",
    "\n",
    "# SVHN grayscale Correlation Matrix\n",
    "ax = axs[1]  # Second subplot for SVHN grayscale\n",
    "im = ax.imshow(cov_svhn_gray_norm, cmap='coolwarm', interpolation='none',vmin=vmin, vmax=vmax)\n",
    "ax.grid(True)\n",
    "ax.set_xticks(np.arange(0, 1024, 32))\n",
    "ax.set_yticks(np.arange(0, 1024, 32))\n",
    "ax.set_xticklabels([])\n",
    "ax.set_yticklabels([])\n",
    "ax.set_title('SVHN Grayscale - Covariance Matrix \\n(1 channel 32x32=1024)')\n",
    "#fig.colorbar(im, ax=ax)\n",
    "\n",
    "# SVHN Correlation Matrix\n",
    "ax = axs[2]  # Third subplot for SVHN\n",
    "im = ax.imshow(cov_svhn_norm, cmap='coolwarm', interpolation='none',vmin=vmin, vmax=vmax)\n",
    "ax.set_title('SVHN RGB - Covariance Matrix \\n(3 channels 32x32 = 3072)')\n",
    "#fig.colorbar(im, ax=ax)\n",
    "fig.colorbar(im, ax=axs, orientation='horizontal', fraction=0.025, pad=0.04)\n",
    "\n",
    "# Display the subplots\n",
    "plt.suptitle('Covariance Matrices (Flattened line by line)', fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3/ APPLYING CORAL METHOD**\n",
    "---\n",
    "With the normalised data, we can now apply the CORAL method to align the source and target distributions. \n",
    "\n",
    "The steps are as follows:<br>\n",
    "1/ Compute the square root of the inverse of the source covariance matrix.<br>\n",
    "2/ Compute the whitened source data.<br>\n",
    "3/ Compute the square root of the target covariance matrix.<br>\n",
    "4/ Compute the aligned source data.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCTIONS TO APPLY CORAL METHOD\n",
    "#################################\n",
    "\n",
    "def get_whitening_matrix(cov, epsilon=1e-5):\n",
    "    '''Compute the whitening matrix from the covariance matrix\n",
    "    input : covariance matrix of SOURCE dataset, epsilon\n",
    "    output : whitening matrix (size of covariance matrix)\n",
    "    '''\n",
    "    # Compute the eigenvalues and eigenvectors of the covariance matrix\n",
    "    eigvals, eigvecs = np.linalg.eigh(cov + epsilon * np.eye(cov.shape[0]))\n",
    "\n",
    "    # Compute the inverse of the square root of the eigenvalues\n",
    "    inv_sqrt_eigvals = 1.0 / np.sqrt(eigvals)\n",
    "\n",
    "    # Construct the whitening matrix\n",
    "    whitening_matrix = np.dot(np.dot(eigvecs, np.diag(inv_sqrt_eigvals)), eigvecs.T)\n",
    "\n",
    "    return whitening_matrix\n",
    "\n",
    "def get_whitened_data(data, mean, whitening_matrix):\n",
    "    '''denoise the data by centering and whitening it\n",
    "    Input: flattenned np.array data, mean, whitening_matrix\n",
    "    '''\n",
    "    # Center the data\n",
    "    centered_data = data - mean\n",
    "\n",
    "    # Apply the whitening matrix\n",
    "    whitened_data = np.dot(centered_data, whitening_matrix)\n",
    "\n",
    "    return whitened_data   \n",
    "\n",
    "def get_coloring_matrix(target_cov):\n",
    "    # Compute the square root of the target covariance matrix\n",
    "    eigvals, eigvecs = np.linalg.eigh(target_cov)\n",
    "    eigvals[eigvals < 0] = 0  # Numerical stability\n",
    "    sqrt_eigvals = np.diag(np.sqrt(eigvals))\n",
    "    coloring_matrix = np.dot(eigvecs, np.dot(sqrt_eigvals, eigvecs.T))\n",
    "\n",
    "    return coloring_matrix\n",
    "\n",
    "def get_colored_data(data, mean, coloring_matrix):\n",
    "    '''denoise the data by centering and coloring it\n",
    "    Input: flattenned np.array data, mean, coloring_matrix\n",
    "    '''\n",
    "    # DO NOT center the data\n",
    "\n",
    "    # Apply the coloring matrix\n",
    "    colored_data = np.dot(data, coloring_matrix)\n",
    "\n",
    "    return colored_data\n",
    "\n",
    "# After whitening and coloring the mean and std of new data needs to be checked and adjusted\n",
    "# shifts or scaling may have occured due to the use of eigenvalues and eigenvectors (not unique)\n",
    "\n",
    "def adjust_mean_std_to_SVHN(data, data_mean, data_std, target_mean, target_std):\n",
    "    \"\"\"\n",
    "    Adjusts the input data (NumPy array) to have the specified target mean and standard deviation,\n",
    "    ensuring the output is a NumPy array.\n",
    "\n",
    "    :param data: Input data as a NumPy array.\n",
    "    :param data_mean: Mean of the input data.\n",
    "    :param data_std: Standard deviation of the input data.\n",
    "    :param target_mean: Target mean for the adjusted data.\n",
    "    :param target_std: Target standard deviation for the adjusted data.\n",
    "    :return: Adjusted data as a NumPy array.\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"colored data - shape, mean, std, min, max:\",data.shape, np.mean(data), np.std(data), np.min(data), np.max(data))\n",
    "\n",
    "    # Convert mean and std to numpy arrays for broadcasting if they aren't already\n",
    "    data_mean = np.array(data_mean)\n",
    "    data_std = np.array(data_std)\n",
    "    target_mean = np.array(target_mean)\n",
    "    target_std = np.array(target_std)\n",
    "    \n",
    "    # Adjust the data\n",
    "    adjusted_data = ((data - data_mean) * (target_std / data_std)) + target_mean\n",
    "    \n",
    "    # Optionally, you can clip the adjusted data to ensure it's within a valid range, like [0, 1]\n",
    "    adjusted_data = np.clip(adjusted_data, 0, 1)\n",
    "    \n",
    "    print(\"adjusted data - shape, mean, std, min, max:\",adjusted_data.shape, np.mean(adjusted_data), np.std(adjusted_data), np.min(adjusted_data), np.max(adjusted_data))\n",
    "    \n",
    "    return adjusted_data\n",
    "\n",
    "def apply_CORAL(source_data, target_data , target_mean=None, target_std=None):\n",
    "    '''Apply CORAL method to source data to make it look like target data\n",
    "    Input: = FLAT NORMALISED NP ARRAYS = source_data, target_data\n",
    "    Output: source_data adjusted to look like target_data\n",
    "    '''\n",
    "    # Compute the covariance matrices\n",
    "    cov_source = np.cov(source_data, rowvar=False)\n",
    "    cov_target = np.cov(target_data, rowvar=False)\n",
    "\n",
    "    # Compute the whitening and coloring matrices\n",
    "    whitening_matrix = get_whitening_matrix(cov_source)\n",
    "    coloring_matrix = get_coloring_matrix(cov_target)\n",
    "\n",
    "    # Apply the whitening and coloring matrices\n",
    "    source_whitened = get_whitened_data(source_data, np.mean(source_data, axis=0), whitening_matrix)\n",
    "    source_colorized = get_colored_data(source_whitened, np.mean(target_data, axis=0), coloring_matrix)\n",
    "\n",
    "    # Adjust the data to the target distribution\n",
    "    if target_mean is not None and target_std is not None:\n",
    "        source_colorized_adjusted = adjust_mean_std_to_SVHN(source_colorized, \n",
    "                        np.mean(source_colorized), np.std(source_colorized), \n",
    "                        target_mean, target_std)\n",
    "    else:\n",
    "        source_colorized_adjusted = adjust_mean_std_to_SVHN(source_colorized, \n",
    "                        np.mean(source_colorized), np.std(source_colorized), \n",
    "                        np.mean(target_data), np.std(target_data))\n",
    "\n",
    "    return source_colorized_adjusted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEMO - CORAL METHOD TO MNIST WITH GRAYSCALE SVHN\n",
    "####################################################\n",
    "\n",
    "gray_colored = apply_CORAL(mnist_norm_np_flat, svhn_gray_norm_np_flat, svhn_mean.cpu().numpy(), svhn_std.cpu().numpy()) # adjust to SVHN gray channel\n",
    "plot_images(gray_colored.reshape(-1, 32, 32), 'MNIST Adjusted to SVHN Grayscale (1 channel)')\n",
    "\n",
    "# DECOMPOSED CORAL METHOD TO MNIST WITH GRAYSCALE SVHN\n",
    "########################################################\n",
    "\n",
    "# Whiten & color & adjust MNIST\n",
    "print('mnist_norm_np_flat shape:',mnist_norm_np_flat.shape)\n",
    "whitening_matrix = get_whitening_matrix(cov_mnist_norm)\n",
    "mnist_whitened = get_whitened_data(mnist_norm_np_flat, np.mean(mnist_norm_np_flat, axis=0), whitening_matrix)\n",
    "coloring_matrix_gray = get_coloring_matrix(cov_svhn_gray_norm)\n",
    "mnist_colorized_gray = get_colored_data(mnist_whitened, np.mean(svhn_gray_norm_np_flat, axis=0), coloring_matrix_gray)\n",
    "\n",
    "# Adjust the data to the SVHN distirbution\n",
    "mnist_like_svhn_gray = adjust_mean_std_to_SVHN(mnist_colorized_gray, \n",
    "                        np.mean(mnist_colorized_gray), np.std(mnist_colorized_gray), \n",
    "                        svhn_mean.cpu().numpy(), svhn_std.cpu().numpy())\n",
    "\n",
    "\n",
    "# show images : whitened, colorized, adjusted\n",
    "plot_images(mnist_whitened.reshape(-1, 32, 32), 'MNIST =Whitened= with MNIST')\n",
    "plot_images(mnist_colorized_gray.reshape(-1, 32, 32), 'MNIST =Colorized= with SVHN Grayscale (1 channel)')\n",
    "mnist_like_svhn_gray_img = mnist_like_svhn_gray.reshape(-1, 32, 32)\n",
    "plot_images(mnist_like_svhn_gray_img, 'MNIST =Adjusted= to SVHN Grayscale (1 channel)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# APPLY CORAL METHOD TO MNIST TRAIN WITH SVHN \n",
    "# (3 channels - red, green, blue + Grayscale)\n",
    "###############################################\n",
    "\n",
    "# MNIST COLORIZED WITH SVHN 3 CHANNELS \n",
    "#-------------------------------------\n",
    "\n",
    "# RED CHANNEL\n",
    "red = svhn_norm_np_flat[:,:1024]\n",
    "red_colored = apply_CORAL(mnist_norm_np_flat, red, svhn_mean_channels[0].cpu().numpy(), svhn_std_channels[0].cpu().numpy()) # adjust to SVHN red channel\n",
    "red_colored_img = red_colored.reshape(-1, 32, 32)\n",
    "plot_images(red_colored_img, 'MNIST Red Channel Adjusted to SVHN Red Channel','Reds')\n",
    "\n",
    "# GREEN CHANNEL\n",
    "green = svhn_norm_np_flat[:,1024:2048]\n",
    "green_colored = apply_CORAL(mnist_norm_np_flat, green, svhn_mean_channels[1].cpu().numpy(), svhn_std_channels[1].cpu().numpy()) # adjust to SVHN green channel\n",
    "green_colored_img = green_colored.reshape(-1, 32, 32)\n",
    "plot_images(green_colored_img, 'MNIST Green Channel Adjusted to SVHN Green Channel','Greens')\n",
    "\n",
    "# BLUE CHANNEL\n",
    "blue = svhn_norm_np_flat[:,2048:]\n",
    "blue_colored = apply_CORAL(mnist_norm_np_flat, blue, svhn_mean_channels[2].cpu().numpy(), svhn_std_channels[2].cpu().numpy()) # adjust to SVHN blue channel\n",
    "blue_colored_img = blue_colored.reshape(-1, 32, 32)\n",
    "plot_images(blue_colored_img, 'MNIST Blue Channel Adjusted to SVHN Blue Channel','Blues')\n",
    "\n",
    "# (COMBINE RED GREEN BLUE CHANNELS)\n",
    "mnist_colorized_RGB = np.zeros((len(mnist_norm_np_flat), 32, 32, 3))\n",
    "mnist_colorized_RGB[:,:,:,0] = red_colored_img\n",
    "mnist_colorized_RGB[:,:,:,1] = green_colored_img\n",
    "mnist_colorized_RGB[:,:,:,2] = blue_colored_img\n",
    "plot_images(mnist_colorized_RGB, 'MNIST Adjusted to SVHN RGB (3 channels)')\n",
    "\n",
    "with open('mnist_colorized_RGB.pkl', 'wb') as f:\n",
    "    pickle.dump(mnist_colorized_RGB, f)\n",
    "\n",
    "# MNIST COLORIZED WITH SVHN GRAYSCALE\n",
    "#-------------------------------------\n",
    "gray = svhn_gray_norm_np_flat\n",
    "gray_colored = apply_CORAL(mnist_norm_np_flat, gray, svhn_mean.cpu().numpy(), svhn_std.cpu().numpy()) # adjust to SVHN gray channel\n",
    "gray_colored_img = gray_colored.reshape(-1, 32, 32)\n",
    "plot_images(gray_colored_img, 'MNIST Adjusted to SVHN Grayscale (1 channel)')\n",
    "\n",
    "with open('mnist_colorized_gray.pkl', 'wb') as f:\n",
    "    pickle.dump(gray_colored_img, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# APPLY CORAL METHOD TO MNIST TEST WITH SVHN \n",
    "# (3 channels - red, green, blue + Grayscale)\n",
    "###############################################\n",
    "\n",
    "\n",
    "# Load the MNIST test dataset\n",
    "MNIST_test = datasets.MNIST(root='./mnist_data/', train=False, transform=transform_mnist, download=True)\n",
    "\n",
    "# Normalize and flatten the MNIST test dataset\n",
    "# --------------------------------------------\n",
    "test = MNIST_test.data.to(device)\n",
    "test = test.float()\n",
    "test = F.interpolate(test.unsqueeze(1), size=(32, 32), mode='nearest').squeeze(1)\n",
    "test = test / 255\n",
    "test = (test - mnist_mean) / mnist_std # normalise with the train datset mean and std\n",
    "test = test.reshape(test.shape[0], -1).cpu().numpy() # flatten\n",
    "print(\"test shape, min, max, mean, std:\",test.shape, np.min(test), np.max(test), np.mean(test), np.std(test))\n",
    "\n",
    "# MNIST COLORIZED WITH SVHN 3 CHANNELS\n",
    "#-------------------------------------\n",
    "\n",
    "# RED CHANNEL\n",
    "red_test = svhn_norm_np_flat[:,:1024]\n",
    "red_colored_test = apply_CORAL(test, red_test, svhn_mean_channels[0].cpu().numpy(), svhn_std_channels[0].cpu().numpy()) # adjust to SVHN red channel\n",
    "red_colored_test_img = red_colored_test.reshape(-1, 32, 32)\n",
    "plot_images(red_colored_test_img, 'MNIST Test Red Channel Adjusted to SVHN Red Channel','Reds')\n",
    "\n",
    "# GREEN CHANNEL\n",
    "green_test = svhn_norm_np_flat[:,1024:2048]\n",
    "green_colored_test = apply_CORAL(test, green_test, svhn_mean_channels[1].cpu().numpy(), svhn_std_channels[1].cpu().numpy()) # adjust to SVHN green channel\n",
    "green_colored_test_img = green_colored_test.reshape(-1, 32, 32)\n",
    "plot_images(green_colored_test_img, 'MNIST Test Green Channel Adjusted to SVHN Green Channel','Greens')\n",
    "\n",
    "# BLUE CHANNEL\n",
    "blue_test = svhn_norm_np_flat[:,2048:]\n",
    "blue_colored_test = apply_CORAL(test, blue_test, svhn_mean_channels[2].cpu().numpy(), svhn_std_channels[2].cpu().numpy()) # adjust to SVHN blue channel\n",
    "blue_colored_test_img = blue_colored_test.reshape(-1, 32, 32)\n",
    "plot_images(blue_colored_test_img, 'MNIST Test Blue Channel Adjusted to SVHN Blue Channel','Blues')\n",
    "\n",
    "# (COMBINE RED GREEN BLUE CHANNELS)\n",
    "mnist_colorized_RGB_test = np.zeros((len(test), 32, 32, 3))\n",
    "mnist_colorized_RGB_test[:,:,:,0] = red_colored_test_img\n",
    "mnist_colorized_RGB_test[:,:,:,1] = green_colored_test_img\n",
    "mnist_colorized_RGB_test[:,:,:,2] = blue_colored_test_img\n",
    "plot_images(mnist_colorized_RGB_test, 'MNIST Test Adjusted to SVHN RGB (3 channels)')\n",
    "with open('mnist_colorized_RGB_test.pkl', 'wb') as f:\n",
    "    pickle.dump(mnist_colorized_RGB_test, f)\n",
    "\n",
    "# MNIST COLORIZED WITH SVHN GRAYSCALE\n",
    "#-------------------------------------\n",
    "gray_test = svhn_gray_norm_np_flat\n",
    "gray_colored_test = apply_CORAL(test, gray_test, svhn_mean.cpu().numpy(), svhn_std.cpu().numpy()) # adjust to SVHN gray channel\n",
    "gray_colored_test_img = gray_colored_test.reshape(-1, 32, 32)\n",
    "plot_images(gray_colored_test_img, 'MNIST Test Adjusted to SVHN Grayscale (1 channel)')\n",
    "with open('mnist_colorized_gray_test.pkl', 'wb') as f:\n",
    "    pickle.dump(gray_colored_test_img, f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4/ APPLYING CORAL METHOD WITH RANDMONESS**\n",
    "---\n",
    "We will apply the CORAL method to the 3 channels of the images and add randomness to the transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# APPLY CORAL METHOD TO MNIST WITH SVHN (TRAIN)\n",
    "###############################################\n",
    "\n",
    "# Apply random coeff from -1 (inversion) to 1 to each channel\n",
    "red_coeff = np.random.rand(len(mnist_norm_np_flat))\n",
    "green_coeff = np.random.rand(len(mnist_norm_np_flat))\n",
    "blue_coeff = np.random.rand(len(mnist_norm_np_flat))\n",
    "\n",
    "red_invert = np.random.choice([1, -1], len(mnist_norm_np_flat))\n",
    "green_invert = np.random.choice([1, -1], len(mnist_norm_np_flat))\n",
    "blue_invert = np.random.choice([1, -1], len(mnist_norm_np_flat))\n",
    "\n",
    "new_red_colored_img = red_colored_img * red_coeff[:, None, None]*red_invert[:, None, None]\n",
    "new_green_colored_img = green_colored_img * green_coeff[:, None, None]*green_invert[:, None, None]\n",
    "new_blue_colored_img = blue_colored_img * blue_coeff[:, None, None]*blue_invert[:, None, None]\n",
    "\n",
    "# Combine the 3 channels with random coefficients\n",
    "new_mnist_colorized_RGB = np.zeros((len(mnist_norm_np_flat), 32, 32, 3))\n",
    "new_mnist_colorized_RGB[:,:,:,0] = new_red_colored_img\n",
    "new_mnist_colorized_RGB[:,:,:,1] = new_green_colored_img\n",
    "new_mnist_colorized_RGB[:,:,:,2] = new_blue_colored_img\n",
    "\n",
    "plot_images(new_mnist_colorized_RGB, 'MNIST Adjusted to SVHN RGB (3 channels)')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5/VISUALISING CENTER CORRELATION WITH SPIRAL TRANSFORMATION OF IMAGE**\n",
    "---\n",
    "spiral goes clockwise from the center of the image to the edges.\n",
    "starts in the center, goes to the top left corner, then to the top right corner, then to the bottom right corner, and finally to the bottom left corner, etc. untol edges are reached.\n",
    "\n",
    "for each spiral will move 2n+1 to the left and the top, and then 2n+2 to the right and to the bottom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SPRIRAL FLATTENING\n",
    "#####################################\n",
    "\n",
    "def spiral_flatten_center_out(image):\n",
    "    N = image.shape[0]\n",
    "    output = np.zeros(N*N, dtype=image.dtype)\n",
    "    x, y = N // 2 - 1, N // 2 - 1  # Start from the center for even dimensions\n",
    "    dx, dy = 0, 1  # Initial direction: right\n",
    "    steps = 1  # Initial steps in the current direction\n",
    "    step_changes = 0  # Counts how many times we've changed steps\n",
    "    index = 0  # Index for the output array\n",
    "\n",
    "    for i in range(N * N):\n",
    "        # Check if current position is valid\n",
    "        if 0 <= x < N and 0 <= y < N:\n",
    "            output[index] = image[x, y]\n",
    "            index += 1\n",
    "        # Move to the next position\n",
    "        x, y = x + dx, y + dy\n",
    "        steps -= 1\n",
    "        # Change direction and update steps\n",
    "        if steps == 0:\n",
    "            dx, dy = -dy, dx  # Rotate direction\n",
    "            step_changes += 1\n",
    "            if step_changes % 2 == 0:\n",
    "                steps = step_changes // 2 + 1\n",
    "            else:\n",
    "                steps = (step_changes + 1) // 2\n",
    "\n",
    "    return output\n",
    "\n",
    "#MNIST\n",
    "\n",
    "data_np = MNIST_train.data.numpy()\n",
    "print('MNIST size',data_np.shape)\n",
    "n_images, height, width = data_np.shape\n",
    "data_spiral = np.zeros((n_images, height * width), dtype=data_np.dtype) # Apply the spiral flattening to each image\n",
    "for i in range(n_images):\n",
    "    data_spiral[i, :] = spiral_flatten_center_out(data_np[i, :, :])\n",
    "cov_mnist_spiral = np.cov(data_spiral, rowvar=False)\n",
    "\n",
    "# SVHN grayscale (by adding 3 channels into 1)\n",
    "data_np = SVHN_train.data # numpy array\n",
    "data_np = np.mean(data_np, axis=1)\n",
    "print(\"SVHN grayscale shape\", data_np.shape)\n",
    "n_images, height, width = data_np.shape\n",
    "data_spiral = np.zeros((n_images, height * width), dtype=data_np.dtype) # Apply the spiral flattening to each channel of each image\n",
    "for i in range(n_images):\n",
    "    data_spiral[i, :] = spiral_flatten_center_out(data_np[i, :, :])\n",
    "cov_SVHN_gray_spiral = np.cov(data_spiral, rowvar=False)\n",
    "\n",
    "#SVHN\n",
    "\n",
    "data_np = SVHN_train.data\n",
    "print(\"SVHN shape\", data_np.shape)\n",
    "n_images, channels, height, width = data_np.shape\n",
    "data_spiral = np.zeros((n_images, channels * height * width), dtype=data_np.dtype) # Apply the spiral flattening to each channel of each image\n",
    "for i in range(n_images):\n",
    "    for j in range(channels):  # data_np is [i,3, :, :] is an image\n",
    "        data_spiral[i, j * height * width:(j + 1) * height * width] = spiral_flatten_center_out(data_np[i, j, :, :])\n",
    "cov_SVHN_spiral = np.cov(data_spiral, rowvar=False)\n",
    "\n",
    "# SHOW 3 CORRELATION MATRICES (SPIRAL FLATTENED CENTER OUT)\n",
    "\n",
    "# Create a figure with subplots\n",
    "fig, axs = plt.subplots(1, 3, figsize=(15, 5.5))  # 1 row, 3 columns\n",
    "vmin = -1\n",
    "vmax = 1\n",
    "\n",
    "# MNIST Correlation Matrix\n",
    "ax = axs[0]  # First subplot for MNIST\n",
    "im = ax.imshow(cov_mnist_spiral, cmap='coolwarm', interpolation='none', vmin=vmin, vmax=vmax)\n",
    "ax.grid(True)\n",
    "ax.set_xticks(np.arange(0, 784, 28))\n",
    "ax.set_yticks(np.arange(0, 784, 28))\n",
    "ax.set_xticklabels([])\n",
    "ax.set_yticklabels([])\n",
    "ax.set_title('MNIST Correlation Matrix \\n(1 channel 28x28=784)')\n",
    "#fig.colorbar(im, ax=ax)\n",
    "\n",
    "# SVHN grayscale Correlation Matrix\n",
    "ax = axs[1]  # Second subplot for SVHN grayscale\n",
    "im = ax.imshow(cov_SVHN_gray_spiral, cmap='coolwarm', interpolation='none', vmin=vmin, vmax=vmax)\n",
    "ax.grid(True)\n",
    "ax.set_xticks(np.arange(0, 1024, 32))\n",
    "ax.set_yticks(np.arange(0, 1024, 32))\n",
    "ax.set_xticklabels([])\n",
    "ax.set_yticklabels([])\n",
    "ax.set_title('SVHN Grayscale Covariance Matrix \\n(1 channel 32x32=1024)')\n",
    "#fig.colorbar(im, ax=ax)\n",
    "\n",
    "# SVHN Correlation Matrix\n",
    "ax = axs[2]  # Third subplot for SVHN\n",
    "im = ax.imshow(cov_SVHN_spiral, cmap='coolwarm', interpolation='none',vmin=vmin, vmax=vmax)\n",
    "ax.grid(True)\n",
    "ax.set_title('SVHN Correlation Matrix \\n(3 channels 32x32 = 3072)')\n",
    "#fig.colorbar(im, ax=ax)\n",
    "fig.colorbar(im, ax=axs, orientation='horizontal', fraction=0.025, pad=0.04)\n",
    "# Display the subplots\n",
    "plt.suptitle('Correlation Matrices (Spiral Flattened Center Out)', fontsize=16)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''##############################################################\n",
    "# TO APPLY WHITENING & COLORIZATION TO THE ORIGINAL IMAGES\n",
    "##############################################################\n",
    "\n",
    "#trasnformation to upload flattened preprocessed data\n",
    "class FlattenTransform:\n",
    "    def __call__(self, x):\n",
    "        return x.view(-1)\n",
    "    \n",
    "transform_mnist = transforms.Compose([\n",
    "    transforms.ToTensor(),  # Convert to tensor value in [0, 1]\n",
    "    transforms.Resize((32, 32), interpolation=Image.NEAREST),  # Resize to 32x32\n",
    "    transforms.Normalize(mnist_mean, mnist_std),  # Normalize with real mean and standard deviation\n",
    "    FlattenTransform(),  # Flattens the images\n",
    "])\n",
    "\n",
    "transform_svhn = transforms.Compose([\n",
    "    transforms.ToTensor(), # Convert to tensor value in [0, 1]\n",
    "    transforms.Normalize(svhn_mean, svhn_std), # Normalize with real mean and standard deviation\n",
    "    FlattenTransform(),  # Flattens the images\n",
    "])\n",
    "\n",
    "MNIST_train_flat = datasets.MNIST(root='./mnist_data/', train=True, transform = transform_mnist, download=True)\n",
    "SVHN_train_flat = datasets.SVHN(root='./svhn_data/', split='train', transform = transform_svhn, download=True)\n",
    "\n",
    "MNIST_train_loader_flat = DataLoader(MNIST_train_flat, batch_size=batch_size, shuffle=False)\n",
    "SVHN_train_loader_flat = DataLoader(SVHN_train_flat, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "print(\"MNIST shape: \", MNIST_train_flat.data.shape)\n",
    "print(\"SVHN shape: \", SVHN_train_flat.data.shape)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DOWNLOAD DATA \n",
    "\n",
    "# DOWNLOAD, RESIZE & NORMALIZE MNIST DATASET  (32x32x3 instead of originl 28x28x1)\n",
    "'''\n",
    "from torchvision import datasets, transforms\n",
    "import torch\n",
    "\n",
    "# Define the transform to resize the image to 32x32 and replicate to 3 channels\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((32, 32)),  # Resize to 32x32\n",
    "    transforms.Grayscale(num_output_channels=3),  # Convert to RGB by replicating channels\n",
    "    transforms.ToTensor(),  # Convert to tensor\n",
    "    transforms.Normalize((0.5,), (0.5,))  # Normalize each channel (assuming mean 0.5, std 0.5 for simplicity)\n",
    "])\n",
    "\n",
    "# Download and load the dataset with the defined transform\n",
    "train_dataset_source = datasets.MNIST(root='./mnist_data/', train=True, transform=transform, download=True)\n",
    "test_dataset_source = datasets.MNIST(root='./mnist_data/', train=False, transform=transform, download=True)\n",
    "\n",
    "# DOWNLOAD, (RESIZE &) NORMALISE, SVHN DATASET (Stret View House Numbers)\n",
    "train_dataset_target = datasets.SVHN(root='./svhn_data/', split='train', transform=transform, download=True) # transform to insure same shape and normalisation\n",
    "test_dataset_target = datasets.SVHN(root='./svhn_data/', split='test', transform=transform, download=True)'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python WSL (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
