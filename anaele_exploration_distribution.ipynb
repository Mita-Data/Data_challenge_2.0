{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CHECKING PIXEL DISTIRBUTION**\n",
    "---\n",
    "\n",
    "***Our train and test dataset are drawn out of 3 different datasets***, which characteristic may vary (different sources ?). We need to check if the pixel distribution among the datasets are equivalent, as composition differ between train and test:<br>\n",
    "  - ***train dataset*** : 1st datbase 29.6%, 2nd database 1.3% and 3rd database 69%.\n",
    "  - ***test dataset*** : 1st dataset 0%, 2nd dataset 1.7% and 3er datase 98.3% \n",
    "  \n",
    "If there are strong pixel distribution differences between datasets, we will need to transform images from 1st and 2nd database to look like images from the 3rd database (cf domain adapatation techniques), because our test dataset comes almost exclusively from the 3rd dataset (98.3%). \n",
    "\n",
    "Also we need to explore ***black and white images*** in the datases, as they would artificially alter the distribution. We create a specific function is_color_image(), to check this in both the train and test dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prerequisites\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "from torchvision.utils import save_image\n",
    "from torch.utils.data import Dataset, DataLoader, ConcatDataset, Subset\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import IPython.display\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from PIL import Image\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------------------------------\n",
    "# DEFINE DEVICE\n",
    "#---------------------------------------\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = \"mps\"\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "print(device)\n",
    "\n",
    "#---------------------------------------\n",
    "# DEFINE DATASET CLASS\n",
    "#---------------------------------------\n",
    "\n",
    "#class Dataset(torch.utils.data.Dataset): # in \"starter notebook code\" dataset is imported from torch.utils.data\n",
    "class Dataset(Dataset):\n",
    "    'Characterizes a dataset for PyTorch'\n",
    "    def __init__(self, df, image_dir):\n",
    "         'Initialization'\n",
    "         self.image_dir = image_dir\n",
    "         self.df = df\n",
    "         self.transform = transforms.ToTensor()\n",
    "         \n",
    "    def __len__(self):\n",
    "        'Denotes the total number of samples'\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generates one sample of data'\n",
    "        # Select sample\n",
    "        row = self.df.loc[index]\n",
    "        filename = row['filename']\n",
    "\n",
    "        # Load data and get label\n",
    "        img = Image.open(f\"{self.image_dir}/{filename}\")  \n",
    "        X = self.transform(img)\n",
    "        # y = row['FaceOcclusion']     \n",
    "        # y = np.float32(y)\n",
    "        # gender = row['gender_id'] # changed to have round values 0 or 1\n",
    "\n",
    "\n",
    "        return X, filename # y, gender, filename\n",
    "\n",
    "#--------------------------------------------------\n",
    "# Compute mean and standard deviation on the pixels\n",
    "#--------------------------------------------------\n",
    "\n",
    "def calculate_mean_std(loader, num_channels=3):\n",
    "    '''Calculate mean and standard deviation of the dataset.\n",
    "    Args:\n",
    "        loader: DataLoader object\n",
    "        num_channels: number of channels\n",
    "    Returns:\n",
    "        mean: mean of the dataset (tensor)\n",
    "        std: standard deviation of the dataset (tensor)\n",
    "    '''\n",
    "    channel_sum = torch.zeros(num_channels).to(device)\n",
    "    channel_squared_sum = torch.zeros(num_channels).to(device)\n",
    "    num_elements = 0\n",
    "\n",
    "    for data, _ in loader:\n",
    "        data = data.to(device)\n",
    "        channel_sum += data.sum(dim=[0, 2, 3])\n",
    "        channel_squared_sum += (data ** 2).sum(dim=[0, 2, 3])\n",
    "        num_elements += data.size(0) * data.size(2) * data.size(3)\n",
    "\n",
    "    mean = channel_sum / num_elements\n",
    "    std = (channel_squared_sum / num_elements - mean ** 2) ** 0.5\n",
    "    return mean, std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOAD IMAGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD DATAFRAMES\n",
    "\n",
    "with open('df_train.pkl', 'rb') as f: df_train = pickle.load(f)\n",
    "with open('df_test.pkl', 'rb') as f: df_test = pickle.load(f)\n",
    "print(df_train.columns)\n",
    "df_train.head(-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1/ Explore weight of black and white images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN - Distribution of color and black and white images (gray scale) in the 3 datasets\n",
    "\n",
    "stats = df_train.groupby('db_number')['count','color','no_color','FaceOcclusion','gender_id'].sum()\n",
    "stats.loc['Total'] = stats.sum()\n",
    "stats['color_ratio'] = stats['color'] / stats['count']\n",
    "stats['FaceOcclusion_ratio'] = stats['FaceOcclusion'] / stats['count'] # average FaceOcclusion\n",
    "stats['color_ratio'] = stats['color_ratio'].map('{:.2%}'.format)\n",
    "stats['gender_ratio'] = stats['gender_id'] / stats['count']\n",
    "stats['gender_ratio'] = stats['gender_ratio'].map('{:.2%}'.format)\n",
    "stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST DATASET - Distribution of color and black and white images (gray scale) in the 3 datasets\n",
    "\n",
    "stats = df_test.groupby('db_number')['count','color','no_color'].sum()\n",
    "stats.loc['Total'] = stats.sum()\n",
    "stats['color_ratio'] = stats['color'] / stats['count']\n",
    "stats['color_ratio'] = stats['color_ratio'].map('{:.2%}'.format)\n",
    "stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "# =======> Black and white images can be removed from the train datasets\n",
    "# !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN - Distribution of color images (gray scale) in the 3 datasets\n",
    "\n",
    "stats_color = df_train[df_train['color']==1].groupby('db_number')[['count','color','no_color','FaceOcclusion','gender_id']].sum()\n",
    "stats_color.loc['Total'] = stats_color.sum()\n",
    "stats_color['color_ratio'] = stats_color['color'] / stats_color['count']\n",
    "stats_color['FaceOcclusion_ratio'] = stats_color['FaceOcclusion'] / stats_color['count'] # average FaceOcclusion\n",
    "stats_color['color_ratio'] = stats_color['color_ratio'].map('{:.2%}'.format)\n",
    "stats_color['gender_ratio'] = stats_color['gender_id'] / stats_color['count']\n",
    "stats_color['gender_ratio'] = stats_color['gender_ratio'].map('{:.2%}'.format)\n",
    "stats_color"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2/ Explore color image pixel distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1/ Train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split dataframes by database source and take only color images\n",
    "df = df_train[df_train['color']==1].reset_index(drop=True)\n",
    "df_1 = df_train[(df_train['db_number'] == 1) & (df_train['color'] == 1)].reset_index(drop=True)\n",
    "df_2 = df_train[(df_train['db_number'] == 2) & (df_train['color'] == 1)].reset_index(drop=True)\n",
    "df_3 = df_train[(df_train['db_number'] == 3) & (df_train['color'] == 1)].reset_index(drop=True)\n",
    "\n",
    "# print shapes\n",
    "print('df shape:', df.shape)\n",
    "print('df_1 shape:', df_1.shape)\n",
    "print('df_2 shape:', df_2.shape)\n",
    "print('df_3 shape:', df_3.shape)\n",
    "\n",
    "# generate datasets for database 1 and 3\n",
    "image_dir = 'Data/crops_100K'\n",
    "set = Dataset(df, image_dir)\n",
    "set_1 = Dataset(df_1, image_dir)\n",
    "set_2 = Dataset(df_2, image_dir)\n",
    "set_3 = Dataset(df_3, image_dir)\n",
    "\n",
    "# Create DataLoaders\n",
    "params = {'batch_size': 1024,\n",
    "          'shuffle': False,\n",
    "          'num_workers': 0}\n",
    "\n",
    "loader = torch.utils.data.DataLoader(set, **params)\n",
    "loader_1 = torch.utils.data.DataLoader(set_1, **params)\n",
    "loader_2 = torch.utils.data.DataLoader(set_2, **params)\n",
    "loader_3 = torch.utils.data.DataLoader(set_3, **params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute mean and std deviation of each channel for each dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train color - mean  tensor([0.5568, 0.4393, 0.3803], device='cuda:0')\n",
      "database 1 color - mean  tensor([0.5638, 0.4305, 0.3626], device='cuda:0')\n",
      "database 2 color - mean  tensor([0.5349, 0.4160, 0.3533], device='cuda:0')\n",
      "database 3 color - mean  tensor([0.5536, 0.4444, 0.3904], device='cuda:0')\n",
      "\n",
      " train color - std tensor([0.2827, 0.2495, 0.2422], device='cuda:0')\n",
      "database 1 color - std tensor([0.2892, 0.2504, 0.2382], device='cuda:0')\n",
      "database 2 color - std tensor([0.3020, 0.2635, 0.2504], device='cuda:0')\n",
      "database 3 color - std tensor([0.2786, 0.2485, 0.2435], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# TRAIN DATASET - Explore mean and standard deviation of the pixels in the 3 databases\n",
    "\n",
    "mean , std = calculate_mean_std(loader, num_channels=3)\n",
    "print('train color - mean ', mean)\n",
    "\n",
    "mean_1, std_1 = calculate_mean_std(loader_1, num_channels=3)\n",
    "print('database 1 color - mean ', mean_1)\n",
    "\n",
    "mean_2, std_2 = calculate_mean_std(loader_2, num_channels=3)\n",
    "print('database 2 color - mean ', mean_2)\n",
    "\n",
    "mean_3, std_3 = calculate_mean_std(loader_3, num_channels=3)\n",
    "print('database 3 color - mean ', mean_3)\n",
    "\n",
    "# Explore the standard deviation of the color images in the 3 databases\n",
    "print('\\n train color - std', std)\n",
    "print('database 1 color - std', std_1)\n",
    "print('database 2 color - std', std_2)\n",
    "print('database 3 color - std', std_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "database 1+2 color - mean  tensor([0.5627, 0.4300, 0.3622], device='cuda:0')\n",
      "database 3 color - mean tensor([0.5536, 0.4444, 0.3904], device='cuda:0')\n",
      "\n",
      "database 1+2 color - std tensor([0.2898, 0.2509, 0.2387], device='cuda:0')\n",
      "database 3 color - std tensor([0.2786, 0.2485, 0.2435], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# concatenate dataset 1 + 2\n",
    "df_12 = pd.concat([df_1, df_2])\n",
    "df_12 = df_12.reset_index(drop=True)\n",
    "set_12 = Dataset(df_12, image_dir)\n",
    "loader_12 = torch.utils.data.DataLoader(set_12, **params)\n",
    "\n",
    "mean_12, std_12 = calculate_mean_std(loader_12, num_channels=3)\n",
    "print('database 1+2 color - mean ', mean_12)\n",
    "print('database 3 color - mean', mean_3)\n",
    "print('\\ndatabase 1+2 color - std', std_12)\n",
    "print('database 3 color - std', std_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# database 1 - mean  tensor([0.5623, 0.4301, 0.3626], device='cuda:0')\n",
    "# database 1 - std tensor([0.2899, 0.2511, 0.2390], device='cuda:0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.2/ Test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test df shape: (30507, 13)\n",
      "test df_1 shape: (0, 13)\n",
      "test df_2 shape: (507, 13)\n",
      "test df_3 shape: (30000, 13)\n"
     ]
    }
   ],
   "source": [
    "# split dataframes by database source and take only color images\n",
    "df_test = df_test[df_test['color']==1].reset_index(drop=True)\n",
    "df_1_test = df_test[(df_test['db_number'] == 1) & (df_test['color'] == 1)].reset_index(drop=True)\n",
    "df_2_test = df_test[(df_test['db_number'] == 2) & (df_test['color'] == 1)].reset_index(drop=True)\n",
    "df_3_test = df_test[(df_test['db_number'] == 3) & (df_test['color'] == 1)].reset_index(drop=True)\n",
    "\n",
    "# print shapes\n",
    "print('test df shape:', df_test.shape)\n",
    "print('test df_1 shape:', df_1_test.shape)\n",
    "print('test df_2 shape:', df_2_test.shape)\n",
    "print('test df_3 shape:', df_3_test.shape)\n",
    "\n",
    "# generate datasets for database 2 and 3\n",
    "image_dir = 'Data/crops_100K'\n",
    "set_test = Dataset(df_test, image_dir)\n",
    "# set_1_test = Dataset(df_1_test, image_dir)\n",
    "set_2_test = Dataset(df_2_test, image_dir)\n",
    "set_3_test = Dataset(df_3_test, image_dir)\n",
    "\n",
    "# Create DataLoaders\n",
    "params = {'batch_size': 1024,\n",
    "          'shuffle': False,\n",
    "          'num_workers': 0}\n",
    "loader_test = torch.utils.data.DataLoader(set_test, **params)\n",
    "# loader_1 = torch.utils.data.DataLoader(set_1, **params)\n",
    "loader_2_test = torch.utils.data.DataLoader(set_2_test, **params)\n",
    "loader_3_test = torch.utils.data.DataLoader(set_3_test, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test color - mean  tensor([0.5367, 0.4498, 0.4070], device='cuda:0')\n",
      "database 2 color - mean  tensor([0.5131, 0.4156, 0.3709], device='cuda:0')\n",
      "database 3 color - mean  tensor([0.5371, 0.4504, 0.4076], device='cuda:0')\n",
      "\n",
      "test (color) - std tensor([0.2854, 0.2618, 0.2594], device='cuda:0')\n",
      "database 2 color - std tensor([0.3149, 0.2817, 0.2707], device='cuda:0')\n",
      "database 3 color - std tensor([0.2849, 0.2614, 0.2591], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# Compute mean and standard deviation of the pixels in the databases 2 and 3\n",
    "\n",
    "mean_test , std_test = calculate_mean_std(loader_test, num_channels=3)\n",
    "print('test color - mean ', mean_test)\n",
    "\n",
    "mean_2_test, std_2_test = calculate_mean_std(loader_2_test, num_channels=3)\n",
    "print('database 2 color - mean ', mean_2_test)\n",
    "\n",
    "mean_3_test, std_3_test = calculate_mean_std(loader_3_test, num_channels=3)\n",
    "print('database 3 color - mean ', mean_3_test)\n",
    "\n",
    "# Explore the standard deviation of the color images in the 3 databases\n",
    "print('\\ntest (color) - std', std_test)\n",
    "print('database 2 color - std', std_2_test)\n",
    "print('database 3 color - std', std_3_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3/ Normalize images ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4/ PIXEL DISTRIBUTION OF THE FACE AREA (MASKED IMAGES)\n",
    "\n",
    "TO BE DONE WITH MEDIAPIPE MASKS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4/ PIXEL DISTRIBUTION - COVARIANCE (2nd order statistics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# NORMALIZED DATA\n",
    "#####################################\n",
    "\n",
    "# MNIST\n",
    "data = MNIST_train.data.to(device)\n",
    "data = data.float() \n",
    "#reshape mnist data from 28x28 to 32x32 pixels\n",
    "data = F.interpolate(data.unsqueeze(1), size=(32, 32), mode='nearest').squeeze(1)\n",
    "data = data / 255\n",
    "#print(\"mnist 32x32 shape\",data.shape)\n",
    "data = (data - mnist_mean) / mnist_std\n",
    "mnist_norm_np_flat = data.reshape(data.shape[0], -1).cpu().numpy()\n",
    "\n",
    "# SVHN grayscale (by averaging 3 channels into 1)\n",
    "data = SVHN_train.data /255\n",
    "#print(type(data))\n",
    "data = torch.tensor(data, dtype=torch.float32).to(device)\n",
    "data = torch.mean(data, axis=1)    # reduce to 1 channel\n",
    "data = (data - svhn_mean) / svhn_std\n",
    "data = data.reshape(data.shape[0], -1)\n",
    "svhn_gray_norm_np_flat = data.cpu().numpy()\n",
    "\n",
    "# SVHN  \n",
    "data = SVHN_train.data / 255\n",
    "data = torch.tensor(data, dtype=torch.float32).to(device)\n",
    "data = (data - svhn_mean) / svhn_std\n",
    "svhn_norm_np = data.cpu().numpy()\n",
    "data = data.reshape(data.shape[0], -1)\n",
    "svhn_norm_np_flat = data.cpu().numpy()\n",
    "\n",
    "print(\"\\nNormalised MNIST min, max & shape    :\",mnist_norm_np_flat.shape, mnist_norm_np_flat.min(),mnist_norm_np_flat.max(), type(mnist_norm_np_flat))\n",
    "print(\"Normalised SVHN gray min, max & shape:\",svhn_gray_norm_np_flat.shape, svhn_gray_norm_np_flat.min(), svhn_gray_norm_np_flat.max(), type(svhn_gray_norm_np_flat))\n",
    "print(\"Normalised SVHN min, max & shape     :\",svhn_norm_np_flat.shape, svhn_norm_np_flat.min(),svhn_norm_np_flat.max(),type(svhn_norm_np_flat))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check normalisatoin for Red Green Blue channel of SVHN\n",
    "\n",
    "print(\"\\nSVHN (x3) mean, std   :\",np.round(np.mean(svhn_norm_np_flat),8), np.std(svhn_norm_np_flat), svhn_norm_np_flat.shape)\n",
    "print(\"- SVHN RED mean , std :\",np.mean(svhn_norm_np_flat[:,:1024]), np.std(svhn_norm_np_flat[:,:1024]), svhn_norm_np_flat[:,:1024].shape)\n",
    "print(\"- SVHN GREEN mean, std:\",np.mean(svhn_norm_np_flat[:,1024:2048]), np.std(svhn_norm_np_flat[:,1024:2048]), svhn_norm_np_flat[:,1024:2048].shape)\n",
    "print(\"- SVHN BLUE mean, std : \",np.mean(svhn_norm_np_flat[:,2048:]), np.std(svhn_norm_np_flat[:,2084,]), svhn_norm_np_flat[:,2048:].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################\n",
    "# print images to check normalisation\n",
    "# values range from -inf to +inf => need to scale to 0-1\n",
    "########################################################\n",
    "\n",
    "def plot_images(images, title, color ='gray', scaled = 1):\n",
    "    fig, axs = plt.subplots(1, 10, figsize=(8, 1))\n",
    "    # standardize the range of the images with min or max\n",
    "    for i in range(10):\n",
    "        if scaled == 1:\n",
    "            scaled_image = (images[i]/scale +0.5)\n",
    "            # print('min max:', np.min(scaled_image),' - ', np.max(scaled_image))\n",
    "            # klip the values to 0-1\t\n",
    "            scaled_image[scaled_image > 1] = 1\n",
    "            scaled_image[scaled_image < 0] = 0\n",
    "        else:\n",
    "            scaled_image = images[i]\n",
    "        axs[i].imshow(scaled_image, cmap= color) # scales images to range 0-1\n",
    "        axs[i].axis('off')\n",
    "    plt.suptitle(title, fontsize=14)\n",
    "    plt.show()\n",
    "\n",
    "high = max( np.max(mnist_norm_np_flat) , np.max(svhn_gray_norm_np_flat) , np.max(svhn_norm_np_flat) )\n",
    "low = min( np.min(mnist_norm_np_flat) , np.min(svhn_gray_norm_np_flat), np.min(svhn_norm_np_flat) )\n",
    "scale = max(abs(high), abs(low))\n",
    "print(\"scale\", scale)\n",
    "\n",
    "# MNIST\n",
    "mnist_norm_np = mnist_norm_np_flat.reshape(-1, 32, 32)\n",
    "plot_images(mnist_norm_np, 'MNIST Normalized')\n",
    "\n",
    "# SVHN grayscale\n",
    "svhn_gray_norm_np = svhn_gray_norm_np_flat.reshape(-1, 32, 32)\n",
    "plot_images(svhn_gray_norm_np, 'SVHN Grayscale Normalized')\n",
    "\n",
    "# SVHN\n",
    "svhn_np_transpose = SVHN_train.data.transpose((0, 2, 3, 1))/255\n",
    "plot_images(svhn_np_transpose, 'SVHN Original', scaled = 0)\n",
    "\n",
    "# SVHN\n",
    "svhn_norm_np_transpose = svhn_norm_np.transpose((0, 2, 3, 1))\n",
    "plot_images(svhn_norm_np_transpose, 'SVHN \"Normalized globally\"')\n",
    "#show red channel in red, green in green and blue in blue\n",
    "plot_images(svhn_norm_np_transpose[:,:,:,0], 'SVHN Normalized Red Channel', color ='Reds')\n",
    "plot_images(svhn_norm_np_transpose[:,:,:,1], 'SVHN Normalized Green Channel', color ='Greens')\n",
    "plot_images(svhn_norm_np_transpose[:,:,:,2], 'SVHN Normalized Blue Channel', color ='Blues')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHOW 3 CORRELATION MATRICES (FLATTENED)\n",
    "##########################################\n",
    "\n",
    "cov_mnist_norm = np.cov(mnist_norm_np_flat, rowvar=False)\n",
    "cov_svhn_gray_norm = np.cov(svhn_gray_norm_np_flat, rowvar=False)\n",
    "cov_svhn_norm = np.cov(svhn_norm_np_flat, rowvar=False)\n",
    "\n",
    "# covariance matrix is correlation matrix beacause the data is normalised\n",
    "\n",
    "# Create a figure with subplots\n",
    "fig, axs = plt.subplots(1, 3, figsize=(15, 5.5))  # 1 row, 3 columns\n",
    "vmin = -1\n",
    "vmax = 1\n",
    "# MNIST Correlation Matrix\n",
    "ax = axs[0]  # First subplot for MNIST\n",
    "im = ax.imshow(cov_mnist_norm, cmap='coolwarm', interpolation='none',vmin=vmin, vmax=vmax)\n",
    "ax.grid(True)\n",
    "ax.set_xticks(np.arange(0, 1024, 32))\n",
    "ax.set_yticks(np.arange(0, 1024, 32))\n",
    "ax.set_xticklabels([])\n",
    "ax.set_yticklabels([])\n",
    "ax.set_title('MNIST - Covariance Matrix \\n(1 channel 32x32=1024)')\n",
    "#fig.colorbar(im, ax=ax, )\n",
    "\n",
    "# SVHN grayscale Correlation Matrix\n",
    "ax = axs[1]  # Second subplot for SVHN grayscale\n",
    "im = ax.imshow(cov_svhn_gray_norm, cmap='coolwarm', interpolation='none',vmin=vmin, vmax=vmax)\n",
    "ax.grid(True)\n",
    "ax.set_xticks(np.arange(0, 1024, 32))\n",
    "ax.set_yticks(np.arange(0, 1024, 32))\n",
    "ax.set_xticklabels([])\n",
    "ax.set_yticklabels([])\n",
    "ax.set_title('SVHN Grayscale - Covariance Matrix \\n(1 channel 32x32=1024)')\n",
    "#fig.colorbar(im, ax=ax)\n",
    "\n",
    "# SVHN Correlation Matrix\n",
    "ax = axs[2]  # Third subplot for SVHN\n",
    "im = ax.imshow(cov_svhn_norm, cmap='coolwarm', interpolation='none',vmin=vmin, vmax=vmax)\n",
    "ax.set_title('SVHN RGB - Covariance Matrix \\n(3 channels 32x32 = 3072)')\n",
    "#fig.colorbar(im, ax=ax)\n",
    "fig.colorbar(im, ax=axs, orientation='horizontal', fraction=0.025, pad=0.04)\n",
    "\n",
    "# Display the subplots\n",
    "plt.suptitle('Covariance Matrices (Flattened line by line)', fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3/ APPLYING CORAL METHOD**\n",
    "---\n",
    "With the normalised data, we can now apply the CORAL method to align the source and target distributions. \n",
    "\n",
    "The steps are as follows:<br>\n",
    "1/ Compute the square root of the inverse of the source covariance matrix.<br>\n",
    "2/ Compute the whitened source data.<br>\n",
    "3/ Compute the square root of the target covariance matrix.<br>\n",
    "4/ Compute the aligned source data.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCTIONS TO APPLY CORAL METHOD\n",
    "#################################\n",
    "\n",
    "def get_whitening_matrix(cov, epsilon=1e-5):\n",
    "    '''Compute the whitening matrix from the covariance matrix\n",
    "    input : covariance matrix of SOURCE dataset, epsilon\n",
    "    output : whitening matrix (size of covariance matrix)\n",
    "    '''\n",
    "    # Compute the eigenvalues and eigenvectors of the covariance matrix\n",
    "    eigvals, eigvecs = np.linalg.eigh(cov + epsilon * np.eye(cov.shape[0]))\n",
    "\n",
    "    # Compute the inverse of the square root of the eigenvalues\n",
    "    inv_sqrt_eigvals = 1.0 / np.sqrt(eigvals)\n",
    "\n",
    "    # Construct the whitening matrix\n",
    "    whitening_matrix = np.dot(np.dot(eigvecs, np.diag(inv_sqrt_eigvals)), eigvecs.T)\n",
    "\n",
    "    return whitening_matrix\n",
    "\n",
    "def get_whitened_data(data, mean, whitening_matrix):\n",
    "    '''denoise the data by centering and whitening it\n",
    "    Input: flattenned np.array data, mean, whitening_matrix\n",
    "    '''\n",
    "    # Center the data\n",
    "    centered_data = data - mean\n",
    "\n",
    "    # Apply the whitening matrix\n",
    "    whitened_data = np.dot(centered_data, whitening_matrix)\n",
    "\n",
    "    return whitened_data   \n",
    "\n",
    "def get_coloring_matrix(target_cov):\n",
    "    # Compute the square root of the target covariance matrix\n",
    "    eigvals, eigvecs = np.linalg.eigh(target_cov)\n",
    "    eigvals[eigvals < 0] = 0  # Numerical stability\n",
    "    sqrt_eigvals = np.diag(np.sqrt(eigvals))\n",
    "    coloring_matrix = np.dot(eigvecs, np.dot(sqrt_eigvals, eigvecs.T))\n",
    "\n",
    "    return coloring_matrix\n",
    "\n",
    "def get_colored_data(data, mean, coloring_matrix):\n",
    "    '''denoise the data by centering and coloring it\n",
    "    Input: flattenned np.array data, mean, coloring_matrix\n",
    "    '''\n",
    "    # DO NOT center the data\n",
    "\n",
    "    # Apply the coloring matrix\n",
    "    colored_data = np.dot(data, coloring_matrix)\n",
    "\n",
    "    return colored_data\n",
    "\n",
    "# After whitening and coloring the mean and std of new data needs to be checked and adjusted\n",
    "# shifts or scaling may have occured due to the use of eigenvalues and eigenvectors (not unique)\n",
    "\n",
    "def adjust_mean_std_to_SVHN(data, data_mean, data_std, target_mean, target_std):\n",
    "    \"\"\"\n",
    "    Adjusts the input data (NumPy array) to have the specified target mean and standard deviation,\n",
    "    ensuring the output is a NumPy array.\n",
    "\n",
    "    :param data: Input data as a NumPy array.\n",
    "    :param data_mean: Mean of the input data.\n",
    "    :param data_std: Standard deviation of the input data.\n",
    "    :param target_mean: Target mean for the adjusted data.\n",
    "    :param target_std: Target standard deviation for the adjusted data.\n",
    "    :return: Adjusted data as a NumPy array.\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"colored data - shape, mean, std, min, max:\",data.shape, np.mean(data), np.std(data), np.min(data), np.max(data))\n",
    "\n",
    "    # Convert mean and std to numpy arrays for broadcasting if they aren't already\n",
    "    data_mean = np.array(data_mean)\n",
    "    data_std = np.array(data_std)\n",
    "    target_mean = np.array(target_mean)\n",
    "    target_std = np.array(target_std)\n",
    "    \n",
    "    # Adjust the data\n",
    "    adjusted_data = ((data - data_mean) * (target_std / data_std)) + target_mean\n",
    "    \n",
    "    # Optionally, you can clip the adjusted data to ensure it's within a valid range, like [0, 1]\n",
    "    adjusted_data = np.clip(adjusted_data, 0, 1)\n",
    "    \n",
    "    print(\"adjusted data - shape, mean, std, min, max:\",adjusted_data.shape, np.mean(adjusted_data), np.std(adjusted_data), np.min(adjusted_data), np.max(adjusted_data))\n",
    "    \n",
    "    return adjusted_data\n",
    "\n",
    "def apply_CORAL(source_data, target_data , target_mean=None, target_std=None):\n",
    "    '''Apply CORAL method to source data to make it look like target data\n",
    "    Input: = FLAT NORMALISED NP ARRAYS = source_data, target_data\n",
    "    Output: source_data adjusted to look like target_data\n",
    "    '''\n",
    "    # Compute the covariance matrices\n",
    "    cov_source = np.cov(source_data, rowvar=False)\n",
    "    cov_target = np.cov(target_data, rowvar=False)\n",
    "\n",
    "    # Compute the whitening and coloring matrices\n",
    "    whitening_matrix = get_whitening_matrix(cov_source)\n",
    "    coloring_matrix = get_coloring_matrix(cov_target)\n",
    "\n",
    "    # Apply the whitening and coloring matrices\n",
    "    source_whitened = get_whitened_data(source_data, np.mean(source_data, axis=0), whitening_matrix)\n",
    "    source_colorized = get_colored_data(source_whitened, np.mean(target_data, axis=0), coloring_matrix)\n",
    "\n",
    "    # Adjust the data to the target distribution\n",
    "    if target_mean is not None and target_std is not None:\n",
    "        source_colorized_adjusted = adjust_mean_std_to_SVHN(source_colorized, \n",
    "                        np.mean(source_colorized), np.std(source_colorized), \n",
    "                        target_mean, target_std)\n",
    "    else:\n",
    "        source_colorized_adjusted = adjust_mean_std_to_SVHN(source_colorized, \n",
    "                        np.mean(source_colorized), np.std(source_colorized), \n",
    "                        np.mean(target_data), np.std(target_data))\n",
    "\n",
    "    return source_colorized_adjusted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEMO - CORAL METHOD TO MNIST WITH GRAYSCALE SVHN\n",
    "####################################################\n",
    "\n",
    "gray_colored = apply_CORAL(mnist_norm_np_flat, svhn_gray_norm_np_flat, svhn_mean.cpu().numpy(), svhn_std.cpu().numpy()) # adjust to SVHN gray channel\n",
    "plot_images(gray_colored.reshape(-1, 32, 32), 'MNIST Adjusted to SVHN Grayscale (1 channel)')\n",
    "\n",
    "# DECOMPOSED CORAL METHOD TO MNIST WITH GRAYSCALE SVHN\n",
    "########################################################\n",
    "\n",
    "# Whiten & color & adjust MNIST\n",
    "print('mnist_norm_np_flat shape:',mnist_norm_np_flat.shape)\n",
    "whitening_matrix = get_whitening_matrix(cov_mnist_norm)\n",
    "mnist_whitened = get_whitened_data(mnist_norm_np_flat, np.mean(mnist_norm_np_flat, axis=0), whitening_matrix)\n",
    "coloring_matrix_gray = get_coloring_matrix(cov_svhn_gray_norm)\n",
    "mnist_colorized_gray = get_colored_data(mnist_whitened, np.mean(svhn_gray_norm_np_flat, axis=0), coloring_matrix_gray)\n",
    "\n",
    "# Adjust the data to the SVHN distirbution\n",
    "mnist_like_svhn_gray = adjust_mean_std_to_SVHN(mnist_colorized_gray, \n",
    "                        np.mean(mnist_colorized_gray), np.std(mnist_colorized_gray), \n",
    "                        svhn_mean.cpu().numpy(), svhn_std.cpu().numpy())\n",
    "\n",
    "\n",
    "# show images : whitened, colorized, adjusted\n",
    "plot_images(mnist_whitened.reshape(-1, 32, 32), 'MNIST =Whitened= with MNIST')\n",
    "plot_images(mnist_colorized_gray.reshape(-1, 32, 32), 'MNIST =Colorized= with SVHN Grayscale (1 channel)')\n",
    "mnist_like_svhn_gray_img = mnist_like_svhn_gray.reshape(-1, 32, 32)\n",
    "plot_images(mnist_like_svhn_gray_img, 'MNIST =Adjusted= to SVHN Grayscale (1 channel)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# APPLY CORAL METHOD TO MNIST TRAIN WITH SVHN \n",
    "# (3 channels - red, green, blue + Grayscale)\n",
    "###############################################\n",
    "\n",
    "# MNIST COLORIZED WITH SVHN 3 CHANNELS \n",
    "#-------------------------------------\n",
    "\n",
    "# RED CHANNEL\n",
    "red = svhn_norm_np_flat[:,:1024]\n",
    "red_colored = apply_CORAL(mnist_norm_np_flat, red, svhn_mean_channels[0].cpu().numpy(), svhn_std_channels[0].cpu().numpy()) # adjust to SVHN red channel\n",
    "red_colored_img = red_colored.reshape(-1, 32, 32)\n",
    "plot_images(red_colored_img, 'MNIST Red Channel Adjusted to SVHN Red Channel','Reds')\n",
    "\n",
    "# GREEN CHANNEL\n",
    "green = svhn_norm_np_flat[:,1024:2048]\n",
    "green_colored = apply_CORAL(mnist_norm_np_flat, green, svhn_mean_channels[1].cpu().numpy(), svhn_std_channels[1].cpu().numpy()) # adjust to SVHN green channel\n",
    "green_colored_img = green_colored.reshape(-1, 32, 32)\n",
    "plot_images(green_colored_img, 'MNIST Green Channel Adjusted to SVHN Green Channel','Greens')\n",
    "\n",
    "# BLUE CHANNEL\n",
    "blue = svhn_norm_np_flat[:,2048:]\n",
    "blue_colored = apply_CORAL(mnist_norm_np_flat, blue, svhn_mean_channels[2].cpu().numpy(), svhn_std_channels[2].cpu().numpy()) # adjust to SVHN blue channel\n",
    "blue_colored_img = blue_colored.reshape(-1, 32, 32)\n",
    "plot_images(blue_colored_img, 'MNIST Blue Channel Adjusted to SVHN Blue Channel','Blues')\n",
    "\n",
    "# (COMBINE RED GREEN BLUE CHANNELS)\n",
    "mnist_colorized_RGB = np.zeros((len(mnist_norm_np_flat), 32, 32, 3))\n",
    "mnist_colorized_RGB[:,:,:,0] = red_colored_img\n",
    "mnist_colorized_RGB[:,:,:,1] = green_colored_img\n",
    "mnist_colorized_RGB[:,:,:,2] = blue_colored_img\n",
    "plot_images(mnist_colorized_RGB, 'MNIST Adjusted to SVHN RGB (3 channels)')\n",
    "\n",
    "with open('mnist_colorized_RGB.pkl', 'wb') as f:\n",
    "    pickle.dump(mnist_colorized_RGB, f)\n",
    "\n",
    "# MNIST COLORIZED WITH SVHN GRAYSCALE\n",
    "#-------------------------------------\n",
    "gray = svhn_gray_norm_np_flat\n",
    "gray_colored = apply_CORAL(mnist_norm_np_flat, gray, svhn_mean.cpu().numpy(), svhn_std.cpu().numpy()) # adjust to SVHN gray channel\n",
    "gray_colored_img = gray_colored.reshape(-1, 32, 32)\n",
    "plot_images(gray_colored_img, 'MNIST Adjusted to SVHN Grayscale (1 channel)')\n",
    "\n",
    "with open('mnist_colorized_gray.pkl', 'wb') as f:\n",
    "    pickle.dump(gray_colored_img, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# APPLY CORAL METHOD TO MNIST TEST WITH SVHN \n",
    "# (3 channels - red, green, blue + Grayscale)\n",
    "###############################################\n",
    "\n",
    "\n",
    "# Load the MNIST test dataset\n",
    "MNIST_test = datasets.MNIST(root='./mnist_data/', train=False, transform=transform_mnist, download=True)\n",
    "\n",
    "# Normalize and flatten the MNIST test dataset\n",
    "# --------------------------------------------\n",
    "test = MNIST_test.data.to(device)\n",
    "test = test.float()\n",
    "test = F.interpolate(test.unsqueeze(1), size=(32, 32), mode='nearest').squeeze(1)\n",
    "test = test / 255\n",
    "test = (test - mnist_mean) / mnist_std # normalise with the train datset mean and std\n",
    "test = test.reshape(test.shape[0], -1).cpu().numpy() # flatten\n",
    "print(\"test shape, min, max, mean, std:\",test.shape, np.min(test), np.max(test), np.mean(test), np.std(test))\n",
    "\n",
    "# MNIST COLORIZED WITH SVHN 3 CHANNELS\n",
    "#-------------------------------------\n",
    "\n",
    "# RED CHANNEL\n",
    "red_test = svhn_norm_np_flat[:,:1024]\n",
    "red_colored_test = apply_CORAL(test, red_test, svhn_mean_channels[0].cpu().numpy(), svhn_std_channels[0].cpu().numpy()) # adjust to SVHN red channel\n",
    "red_colored_test_img = red_colored_test.reshape(-1, 32, 32)\n",
    "plot_images(red_colored_test_img, 'MNIST Test Red Channel Adjusted to SVHN Red Channel','Reds')\n",
    "\n",
    "# GREEN CHANNEL\n",
    "green_test = svhn_norm_np_flat[:,1024:2048]\n",
    "green_colored_test = apply_CORAL(test, green_test, svhn_mean_channels[1].cpu().numpy(), svhn_std_channels[1].cpu().numpy()) # adjust to SVHN green channel\n",
    "green_colored_test_img = green_colored_test.reshape(-1, 32, 32)\n",
    "plot_images(green_colored_test_img, 'MNIST Test Green Channel Adjusted to SVHN Green Channel','Greens')\n",
    "\n",
    "# BLUE CHANNEL\n",
    "blue_test = svhn_norm_np_flat[:,2048:]\n",
    "blue_colored_test = apply_CORAL(test, blue_test, svhn_mean_channels[2].cpu().numpy(), svhn_std_channels[2].cpu().numpy()) # adjust to SVHN blue channel\n",
    "blue_colored_test_img = blue_colored_test.reshape(-1, 32, 32)\n",
    "plot_images(blue_colored_test_img, 'MNIST Test Blue Channel Adjusted to SVHN Blue Channel','Blues')\n",
    "\n",
    "# (COMBINE RED GREEN BLUE CHANNELS)\n",
    "mnist_colorized_RGB_test = np.zeros((len(test), 32, 32, 3))\n",
    "mnist_colorized_RGB_test[:,:,:,0] = red_colored_test_img\n",
    "mnist_colorized_RGB_test[:,:,:,1] = green_colored_test_img\n",
    "mnist_colorized_RGB_test[:,:,:,2] = blue_colored_test_img\n",
    "plot_images(mnist_colorized_RGB_test, 'MNIST Test Adjusted to SVHN RGB (3 channels)')\n",
    "with open('mnist_colorized_RGB_test.pkl', 'wb') as f:\n",
    "    pickle.dump(mnist_colorized_RGB_test, f)\n",
    "\n",
    "# MNIST COLORIZED WITH SVHN GRAYSCALE\n",
    "#-------------------------------------\n",
    "gray_test = svhn_gray_norm_np_flat\n",
    "gray_colored_test = apply_CORAL(test, gray_test, svhn_mean.cpu().numpy(), svhn_std.cpu().numpy()) # adjust to SVHN gray channel\n",
    "gray_colored_test_img = gray_colored_test.reshape(-1, 32, 32)\n",
    "plot_images(gray_colored_test_img, 'MNIST Test Adjusted to SVHN Grayscale (1 channel)')\n",
    "with open('mnist_colorized_gray_test.pkl', 'wb') as f:\n",
    "    pickle.dump(gray_colored_test_img, f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4/ APPLYING CORAL METHOD WITH RANDMONESS**\n",
    "---\n",
    "We will apply the CORAL method to the 3 channels of the images and add randomness to the transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# APPLY CORAL METHOD TO MNIST WITH SVHN (TRAIN)\n",
    "###############################################\n",
    "\n",
    "# Apply random coeff from -1 (inversion) to 1 to each channel\n",
    "red_coeff = np.random.rand(len(mnist_norm_np_flat))\n",
    "green_coeff = np.random.rand(len(mnist_norm_np_flat))\n",
    "blue_coeff = np.random.rand(len(mnist_norm_np_flat))\n",
    "\n",
    "red_invert = np.random.choice([1, -1], len(mnist_norm_np_flat))\n",
    "green_invert = np.random.choice([1, -1], len(mnist_norm_np_flat))\n",
    "blue_invert = np.random.choice([1, -1], len(mnist_norm_np_flat))\n",
    "\n",
    "new_red_colored_img = red_colored_img * red_coeff[:, None, None]*red_invert[:, None, None]\n",
    "new_green_colored_img = green_colored_img * green_coeff[:, None, None]*green_invert[:, None, None]\n",
    "new_blue_colored_img = blue_colored_img * blue_coeff[:, None, None]*blue_invert[:, None, None]\n",
    "\n",
    "# Combine the 3 channels with random coefficients\n",
    "new_mnist_colorized_RGB = np.zeros((len(mnist_norm_np_flat), 32, 32, 3))\n",
    "new_mnist_colorized_RGB[:,:,:,0] = new_red_colored_img\n",
    "new_mnist_colorized_RGB[:,:,:,1] = new_green_colored_img\n",
    "new_mnist_colorized_RGB[:,:,:,2] = new_blue_colored_img\n",
    "\n",
    "plot_images(new_mnist_colorized_RGB, 'MNIST Adjusted to SVHN RGB (3 channels)')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5/VISUALISING CENTER CORRELATION WITH SPIRAL TRANSFORMATION OF IMAGE**\n",
    "---\n",
    "spiral goes clockwise from the center of the image to the edges.\n",
    "starts in the center, goes to the top left corner, then to the top right corner, then to the bottom right corner, and finally to the bottom left corner, etc. untol edges are reached.\n",
    "\n",
    "for each spiral will move 2n+1 to the left and the top, and then 2n+2 to the right and to the bottom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SPRIRAL FLATTENING\n",
    "#####################################\n",
    "\n",
    "def spiral_flatten_center_out(image):\n",
    "    N = image.shape[0]\n",
    "    output = np.zeros(N*N, dtype=image.dtype)\n",
    "    x, y = N // 2 - 1, N // 2 - 1  # Start from the center for even dimensions\n",
    "    dx, dy = 0, 1  # Initial direction: right\n",
    "    steps = 1  # Initial steps in the current direction\n",
    "    step_changes = 0  # Counts how many times we've changed steps\n",
    "    index = 0  # Index for the output array\n",
    "\n",
    "    for i in range(N * N):\n",
    "        # Check if current position is valid\n",
    "        if 0 <= x < N and 0 <= y < N:\n",
    "            output[index] = image[x, y]\n",
    "            index += 1\n",
    "        # Move to the next position\n",
    "        x, y = x + dx, y + dy\n",
    "        steps -= 1\n",
    "        # Change direction and update steps\n",
    "        if steps == 0:\n",
    "            dx, dy = -dy, dx  # Rotate direction\n",
    "            step_changes += 1\n",
    "            if step_changes % 2 == 0:\n",
    "                steps = step_changes // 2 + 1\n",
    "            else:\n",
    "                steps = (step_changes + 1) // 2\n",
    "\n",
    "    return output\n",
    "\n",
    "#MNIST\n",
    "\n",
    "data_np = MNIST_train.data.numpy()\n",
    "print('MNIST size',data_np.shape)\n",
    "n_images, height, width = data_np.shape\n",
    "data_spiral = np.zeros((n_images, height * width), dtype=data_np.dtype) # Apply the spiral flattening to each image\n",
    "for i in range(n_images):\n",
    "    data_spiral[i, :] = spiral_flatten_center_out(data_np[i, :, :])\n",
    "cov_mnist_spiral = np.cov(data_spiral, rowvar=False)\n",
    "\n",
    "# SVHN grayscale (by adding 3 channels into 1)\n",
    "data_np = SVHN_train.data # numpy array\n",
    "data_np = np.mean(data_np, axis=1)\n",
    "print(\"SVHN grayscale shape\", data_np.shape)\n",
    "n_images, height, width = data_np.shape\n",
    "data_spiral = np.zeros((n_images, height * width), dtype=data_np.dtype) # Apply the spiral flattening to each channel of each image\n",
    "for i in range(n_images):\n",
    "    data_spiral[i, :] = spiral_flatten_center_out(data_np[i, :, :])\n",
    "cov_SVHN_gray_spiral = np.cov(data_spiral, rowvar=False)\n",
    "\n",
    "#SVHN\n",
    "\n",
    "data_np = SVHN_train.data\n",
    "print(\"SVHN shape\", data_np.shape)\n",
    "n_images, channels, height, width = data_np.shape\n",
    "data_spiral = np.zeros((n_images, channels * height * width), dtype=data_np.dtype) # Apply the spiral flattening to each channel of each image\n",
    "for i in range(n_images):\n",
    "    for j in range(channels):  # data_np is [i,3, :, :] is an image\n",
    "        data_spiral[i, j * height * width:(j + 1) * height * width] = spiral_flatten_center_out(data_np[i, j, :, :])\n",
    "cov_SVHN_spiral = np.cov(data_spiral, rowvar=False)\n",
    "\n",
    "# SHOW 3 CORRELATION MATRICES (SPIRAL FLATTENED CENTER OUT)\n",
    "\n",
    "# Create a figure with subplots\n",
    "fig, axs = plt.subplots(1, 3, figsize=(15, 5.5))  # 1 row, 3 columns\n",
    "vmin = -1\n",
    "vmax = 1\n",
    "\n",
    "# MNIST Correlation Matrix\n",
    "ax = axs[0]  # First subplot for MNIST\n",
    "im = ax.imshow(cov_mnist_spiral, cmap='coolwarm', interpolation='none', vmin=vmin, vmax=vmax)\n",
    "ax.grid(True)\n",
    "ax.set_xticks(np.arange(0, 784, 28))\n",
    "ax.set_yticks(np.arange(0, 784, 28))\n",
    "ax.set_xticklabels([])\n",
    "ax.set_yticklabels([])\n",
    "ax.set_title('MNIST Correlation Matrix \\n(1 channel 28x28=784)')\n",
    "#fig.colorbar(im, ax=ax)\n",
    "\n",
    "# SVHN grayscale Correlation Matrix\n",
    "ax = axs[1]  # Second subplot for SVHN grayscale\n",
    "im = ax.imshow(cov_SVHN_gray_spiral, cmap='coolwarm', interpolation='none', vmin=vmin, vmax=vmax)\n",
    "ax.grid(True)\n",
    "ax.set_xticks(np.arange(0, 1024, 32))\n",
    "ax.set_yticks(np.arange(0, 1024, 32))\n",
    "ax.set_xticklabels([])\n",
    "ax.set_yticklabels([])\n",
    "ax.set_title('SVHN Grayscale Covariance Matrix \\n(1 channel 32x32=1024)')\n",
    "#fig.colorbar(im, ax=ax)\n",
    "\n",
    "# SVHN Correlation Matrix\n",
    "ax = axs[2]  # Third subplot for SVHN\n",
    "im = ax.imshow(cov_SVHN_spiral, cmap='coolwarm', interpolation='none',vmin=vmin, vmax=vmax)\n",
    "ax.grid(True)\n",
    "ax.set_title('SVHN Correlation Matrix \\n(3 channels 32x32 = 3072)')\n",
    "#fig.colorbar(im, ax=ax)\n",
    "fig.colorbar(im, ax=axs, orientation='horizontal', fraction=0.025, pad=0.04)\n",
    "# Display the subplots\n",
    "plt.suptitle('Correlation Matrices (Spiral Flattened Center Out)', fontsize=16)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''##############################################################\n",
    "# TO APPLY WHITENING & COLORIZATION TO THE ORIGINAL IMAGES\n",
    "##############################################################\n",
    "\n",
    "#trasnformation to upload flattened preprocessed data\n",
    "class FlattenTransform:\n",
    "    def __call__(self, x):\n",
    "        return x.view(-1)\n",
    "    \n",
    "transform_mnist = transforms.Compose([\n",
    "    transforms.ToTensor(),  # Convert to tensor value in [0, 1]\n",
    "    transforms.Resize((32, 32), interpolation=Image.NEAREST),  # Resize to 32x32\n",
    "    transforms.Normalize(mnist_mean, mnist_std),  # Normalize with real mean and standard deviation\n",
    "    FlattenTransform(),  # Flattens the images\n",
    "])\n",
    "\n",
    "transform_svhn = transforms.Compose([\n",
    "    transforms.ToTensor(), # Convert to tensor value in [0, 1]\n",
    "    transforms.Normalize(svhn_mean, svhn_std), # Normalize with real mean and standard deviation\n",
    "    FlattenTransform(),  # Flattens the images\n",
    "])\n",
    "\n",
    "MNIST_train_flat = datasets.MNIST(root='./mnist_data/', train=True, transform = transform_mnist, download=True)\n",
    "SVHN_train_flat = datasets.SVHN(root='./svhn_data/', split='train', transform = transform_svhn, download=True)\n",
    "\n",
    "MNIST_train_loader_flat = DataLoader(MNIST_train_flat, batch_size=batch_size, shuffle=False)\n",
    "SVHN_train_loader_flat = DataLoader(SVHN_train_flat, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "print(\"MNIST shape: \", MNIST_train_flat.data.shape)\n",
    "print(\"SVHN shape: \", SVHN_train_flat.data.shape)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DOWNLOAD DATA \n",
    "\n",
    "# DOWNLOAD, RESIZE & NORMALIZE MNIST DATASET  (32x32x3 instead of originl 28x28x1)\n",
    "'''\n",
    "from torchvision import datasets, transforms\n",
    "import torch\n",
    "\n",
    "# Define the transform to resize the image to 32x32 and replicate to 3 channels\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((32, 32)),  # Resize to 32x32\n",
    "    transforms.Grayscale(num_output_channels=3),  # Convert to RGB by replicating channels\n",
    "    transforms.ToTensor(),  # Convert to tensor\n",
    "    transforms.Normalize((0.5,), (0.5,))  # Normalize each channel (assuming mean 0.5, std 0.5 for simplicity)\n",
    "])\n",
    "\n",
    "# Download and load the dataset with the defined transform\n",
    "train_dataset_source = datasets.MNIST(root='./mnist_data/', train=True, transform=transform, download=True)\n",
    "test_dataset_source = datasets.MNIST(root='./mnist_data/', train=False, transform=transform, download=True)\n",
    "\n",
    "# DOWNLOAD, (RESIZE &) NORMALISE, SVHN DATASET (Stret View House Numbers)\n",
    "train_dataset_target = datasets.SVHN(root='./svhn_data/', split='train', transform=transform, download=True) # transform to insure same shape and normalisation\n",
    "test_dataset_target = datasets.SVHN(root='./svhn_data/', split='test', transform=transform, download=True)'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python WSL (myenv)",
   "language": "python",
   "name": "myenv"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
